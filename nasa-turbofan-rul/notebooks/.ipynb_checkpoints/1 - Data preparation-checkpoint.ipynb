{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance using Machine Learning on Sagemaker\n",
    "*Part 1 - Data preparation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "Directory structure to run this notebook:\n",
    "```\n",
    "sagemaker-predictive-maintenance\n",
    "|\n",
    "+--- data\n",
    "|   |\n",
    "|   +--- interim: intermediate data we can manipulate and process\n",
    "|   |\n",
    "|   \\--- raw: *immutable* data downloaded from the source website\n",
    "|\n",
    "+--- notebooks: all the notebooks are positionned here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "Imagine you are the manager at a manufacturing company responsible for monitoring assembly lines. Each assembly line contains multiple kinds of machines that must work continuously and reliably to produce ready-to-ship products as can be seen in the image below. IoT sensors placed on these machines monitor electricity consumption, noise generated, vibration, temperature and various other measurable quantities that are used to monitor the health of each machine. Sudden breakdown of any of these machines across multiple assembly lines will lead to:\n",
    "\n",
    "* Unscheduled downtime and resulting delays in delivering your product to market\n",
    "* Cost incurred due to delays, and hiring maintenance workers to repair and possibly replace parts of the machine that caused the breakdown\n",
    "\n",
    "You have been tasked with researching a technique called “predictive maintenance”, especially after your competitors Advantech, Inc. have published a report (http://www.advantech.com/industrial-automation/industry4.0/pms#my_cen). Additionally, you are intrigued to see if Machine Learning can help with this problem. Your team's collective research notes regarding a potential proof-of-concept that you will be building is included here.\n",
    "\n",
    "## Reactive, Predictive or Preventive Maintenance\n",
    "---\n",
    "Maintenance schedules in typical manufacturing and energy companies that involve large number of machines performing tasks are typically a result of “reactive” or “preventive” maintenance. A reactive maintenance task is scheduled if a machine breaks down (or fails), or is operating in a known degrade state of operation. Preventive maintenance is triggered by usage or time or a fixed schedule. As an example, for car owners, reactive maintenance occurs after there is an failure of a component (stalled engine, punctured tire, etc.), whereas preventive maintenance occurs on a fixed schedule (for example, tire rotation or oil change every 10000 miles) even though there may not be a need for doing so.\n",
    "\n",
    "“Predictive” maintenance implies that maintenance is scheduled when a system predicts the possible occurrence of a failure even in the future. This solves problems that are common in reactive and preventive maintenance - 1. reactive maintenance adds unnecessary time and cost to project schedules, since maintenance workers are deployed only after discovery of a failure event; and 2. preventive maintenance adds unnecessarily frequent maintenance tasks, therefore increasing wait times and costs for the end user. Currently, predictive maintenance techniques involve simple monitoring-and-thresholding, or statistical techniques to identify anomalies from sensor data. However, these techniques are limited to use by Subject Matter Experts (SMEs) and depend on human-generated thresholds. With Machine Learning (ML), it is possible to train models to detect abnormal patterns from sensor data. The trained ML model does not require rules or pre-programmed thresholds, and vast amounts of data can be analyzed repeatably with no need of human involvement.\n",
    "\n",
    "## NASA Turbofan Engine Fault Dataset\n",
    "---\n",
    "### Background\n",
    "\n",
    "NASA's Prognostic Center of Excellence established a repository with datasets to be used for benchmarking prognostics and predictive maintenance related algorithms. Among these datasets involves data from a turbofan engine simulation model C-MAPPS (or Commercial Modular Aero Propulsion System Simulation). The references section contains details about the over 100 publications using this dataset. C-MAPPS is a tool used to generate health, control and engine parameters from a simulated turbofan engine. A custom code wrapper was used to inject synthetic faults and continuous degradation trends into a time series of sensor data. Some high level characteristics of this dataset are as follows:\n",
    "\n",
    "1. The data obtained is from a **high fidelity simulation** of a turbofan engine, but closely models the sensor values of an actual engine.\n",
    "2. **Synthetic noise** was added to the dataset to replicate real-world scenarios.\n",
    "3. The effects of faults are masked due to operational conditions, which is a common trait of most real world systems.\n",
    "\n",
    "Dataset can be downloaded from here: https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some datasets are missing, create working directories and download original dataset from the NASA repository.\n",
      "--2020-05-11 11:49:36--  https://ti.arc.nasa.gov/c/6/\n",
      "Resolving ti.arc.nasa.gov (ti.arc.nasa.gov)... 128.102.105.66, 2001:4d0:6311:2227:14b6:372b:2078:2a94\n",
      "Connecting to ti.arc.nasa.gov (ti.arc.nasa.gov)|128.102.105.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://ti.arc.nasa.gov/m/project/prognostic-repository/CMAPSSData.zip [following]\n",
      "--2020-05-11 11:49:37--  https://ti.arc.nasa.gov/m/project/prognostic-repository/CMAPSSData.zip\n",
      "Reusing existing connection to ti.arc.nasa.gov:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12425978 (12M) [application/zip]\n",
      "Saving to: ‘../data/raw/CMAPSSData.zip’\n",
      "\n",
      "../data/raw/CMAPSSD 100%[===================>]  11.85M  5.45MB/s    in 2.2s    \n",
      "\n",
      "2020-05-11 11:49:39 (5.45 MB/s) - ‘../data/raw/CMAPSSData.zip’ saved [12425978/12425978]\n",
      "\n",
      "Archive:  ../data/raw/CMAPSSData.zip\n",
      "  inflating: ../data/raw/Damage Propagation Modeling.pdf  \n",
      "  inflating: ../data/raw/readme.txt  \n",
      "  inflating: ../data/raw/RUL_FD001.txt  \n",
      "  inflating: ../data/raw/RUL_FD002.txt  \n",
      "  inflating: ../data/raw/RUL_FD003.txt  \n",
      "  inflating: ../data/raw/RUL_FD004.txt  \n",
      "  inflating: ../data/raw/test_FD001.txt  \n",
      "  inflating: ../data/raw/test_FD002.txt  \n",
      "  inflating: ../data/raw/test_FD003.txt  \n",
      "  inflating: ../data/raw/test_FD004.txt  \n",
      "  inflating: ../data/raw/train_FD001.txt  \n",
      "  inflating: ../data/raw/train_FD002.txt  \n",
      "  inflating: ../data/raw/train_FD003.txt  \n",
      "  inflating: ../data/raw/train_FD004.txt  \n"
     ]
    }
   ],
   "source": [
    "ok = True\n",
    "ok = ok and os.path.exists('../data/interim/train_FD001.txt')\n",
    "ok = ok and os.path.exists('../data/interim/test_FD001.txt')\n",
    "ok = ok and os.path.exists('../data/interim/RUL_FD001.txt')\n",
    "ok = ok and os.path.exists('../data/raw')\n",
    "\n",
    "if (ok):\n",
    "    print('Working directories and datasets already exist.')\n",
    "\n",
    "else:\n",
    "    print('Some datasets are missing, create working directories and download original dataset from the NASA repository.')\n",
    "    \n",
    "    # Making sure the raw data targets already exists:\n",
    "    os.makedirs('../data/raw', exist_ok=True)\n",
    "    os.makedirs('../data/interim', exist_ok=True)\n",
    "\n",
    "    # Download the dataset from the NASA repository, unzip it and set\n",
    "    # aside the first training file to work on:\n",
    "    !wget https://ti.arc.nasa.gov/c/6/ --output-document=../data/raw/CMAPSSData.zip\n",
    "    !unzip ../data/raw/CMAPSSData.zip -d ../data/raw\n",
    "    !cp ../data/raw/train_FD001.txt ../data/interim/train_FD001.txt\n",
    "    !cp ../data/raw/test_FD001.txt ../data/interim/test_FD001.txt\n",
    "    !cp ../data/raw/RUL_FD001.txt ../data/interim/RUL_FD001.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details\n",
    "Datasets consist of multiple **multivariate** time series. Each data set is further divided into training and test subsets. Each time series is from a different engine (`unit number`) i.e., the data can be considered to be from a fleet of engines of the same type. Each engine starts with different degrees of initial wear and manufacturing variation which is unknown to the user. This wear and variation is considered normal, i.e., it is not considered a fault condition. There are three operational settings that have a substantial effect on engine performance. These settings are also included in the data (`operational setting 1`, `operational setting 2` and `operational setting 3`). The data (`sensor measurement 1` to `sensor measurement 21`) is contaminated with **sensor noise**.\n",
    "\n",
    "The engine is operating normally at the start of each time series, and develops a fault at some point during the series. In the training set, the fault grows in magnitude until system failure. In the test set, the time series ends some time prior to system failure. The objective of the competition is to **predict the number of remaining operational cycles before failure in the test set**, i.e., the number of operational cycles after the last cycle that the engine will continue to operate. Also provided a vector of true Remaining Useful Life (RUL) values for the test data.\n",
    "\n",
    "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:\n",
    "\n",
    "1. `unit number`\n",
    "2. `time, in cycles`\n",
    "3. `operational setting 1`\n",
    "4. `operational setting 2`\n",
    "5. `operational setting 3`\n",
    "6. `sensor measurement 1`\n",
    "7. `sensor measurement 2`\n",
    "8. ...\n",
    "9. `sensor measurement 21`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20631, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1       2       3      4       5       6        7        8      9   \\\n",
       "0   1   1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60  14.62   \n",
       "1   1   2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14  14.62   \n",
       "2   1   3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20  14.62   \n",
       "3   1   4  0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87  14.62   \n",
       "4   1   5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22  14.62   \n",
       "\n",
       "   ...      16       17       18      19    20   21    22     23     24  \\\n",
       "0  ...  521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06   \n",
       "1  ...  522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00   \n",
       "2  ...  522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95   \n",
       "3  ...  522.86  2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88   \n",
       "4  ...  522.19  2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90   \n",
       "\n",
       "        25  \n",
       "0  23.4190  \n",
       "1  23.4236  \n",
       "2  23.3442  \n",
       "3  23.3739  \n",
       "4  23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../data/interim/train_FD001.txt'\n",
    "data = pd.read_csv(dataset_path, header=None, sep=' ')\n",
    "data.dropna(axis='columns', how='all', inplace=True)\n",
    "print('Shape:', data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting readable column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'unit_number',\n",
    "    'time',\n",
    "    'operational_setting_1',\n",
    "    'operational_setting_2',\n",
    "    'operational_setting_3',\n",
    "] + ['sensor_measurement_{}'.format(s) for s in range(1,22)]\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column with the remaining useful lifetime (RUL):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a RUL column and group the data by unit_number:\n",
    "data['rul'] = 0\n",
    "grouped_data = data.groupby(by='unit_number')\n",
    "\n",
    "# Loops through each unit number to get the lifecycle counts:\n",
    "for unit, rul in enumerate(grouped_data.count()['time']):\n",
    "    current_df = data[data['unit_number'] == (unit+1)].copy()\n",
    "    current_df['rul'] = rul - current_df['time']\n",
    "    data[data['unit_number'] == (unit+1)] = current_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing data for the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data' (DataFrame)\n",
      "Stored 'columns' (list)\n"
     ]
    }
   ],
   "source": [
    "%store data\n",
    "%store columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
