{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance using Machine Learning on Sagemaker\n",
    "*Part 4 - Model training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "Directory structure to run this notebook:\n",
    "```\n",
    "nasa-turbofan-rul-lstm\n",
    "|\n",
    "+--- data\n",
    "|   |\n",
    "|   +--- interim: intermediate data we can manipulate and process\n",
    "|   |\n",
    "|   \\--- raw: *immutable* data downloaded from the source website\n",
    "|\n",
    "+--- notebooks: all the notebooks are positionned here\n",
    "|\n",
    "+--- src: the training script will be located here, along with some utility scripts\n",
    "```\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import errno\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import mxnet.gluon as G\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initializing random seeds:\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "sns.set_style('darkgrid')\n",
    "sys.path.append('../src')\n",
    "\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "import lstm_utils\n",
    "\n",
    "INTERIM_DATA = '../data/interim'\n",
    "PROCESSED_DATA = '../data/processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Sagemaker & AWS specific libraries: we also obtain the IAM role arn used to give training and hosting access to your data. Here we use the get_execution_role function to obtain the role arn which was specified when creating the notebook. We also configure the container image to be used for the region that we are running in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# S3 bucket for saving code and model artifacts:\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Bucket location where custom code will be saved in the tar.gz format:\n",
    "custom_code_upload_location = 's3://{}/nasa-rul-lstm/code'.format(bucket)\n",
    "\n",
    "# Bucket location where results of model training will be saved:\n",
    "model_artifacts_location = 's3://{}/nasa-rul-lstm/artifacts'.format(bucket)\n",
    "\n",
    "# S3 Data location:\n",
    "train_data_location = 's3://{}/nasa-rul-lstm/data'.format(bucket)\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data channel found in notebook environment.\n",
      "Loaded \"data_channels\"\n"
     ]
    }
   ],
   "source": [
    "# Load data from the notebook local storage:\n",
    "%store -r data_channels\n",
    "\n",
    "success_msg = 'Loaded \"data_channels\"'\n",
    "if 'data_channels' not in locals():\n",
    "    print('Nothing in notebook store, trying to load from disk.')\n",
    "    try:\n",
    "        local_path = '../data/processed'\n",
    "        with open(os.path.join(local_path, 'data_channels.txt'), 'r') as f:\n",
    "            data_channels = eval(f.readline())\n",
    "            \n",
    "        print(success_msg)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if (e.errno == errno.ENOENT):\n",
    "            print('Files not found to load data channel from: you need to execute the previous notebook.')\n",
    "            \n",
    "else:\n",
    "    print('Data channel found in notebook environment.')\n",
    "    print(success_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "### Training script\n",
    "The `nasa_rul_training.py` script provides all the code we need for training and hosting a SageMaker model. The script also checkpoints the model at the end of every epoch and saves the model graph, params and optimizer state in the model artifacts archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "training_job_name = 'nasa-rul-lstm'\n",
    "\n",
    "rul_estimator = MXNet(\n",
    "    entry_point='../src/nasa_rul_training.py',\n",
    "    role=role,\n",
    "    output_path=model_artifacts_location,\n",
    "    code_location=custom_code_upload_location,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    distributions={'parameter_server': {'enabled': True}},\n",
    "    hyperparameters={\n",
    "        'batch-size': 16,\n",
    "        'learning-rate': 0.0034711926221743473,\n",
    "        'sequence-length': 20,\n",
    "        'hidden-size': 122,\n",
    "        'num-layers': 3,\n",
    "        'epoch': 50,\n",
    "    },\n",
    "    metric_definitions=[\n",
    "        {'Name': 'train:loss', 'Regex': 'training loss: (\\S+)'},\n",
    "        {'Name': 'train:rmse', 'Regex': 'training rmse: (\\S+)'}\n",
    "    ],\n",
    "    base_job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch a single training job, you can use the following commands:\n",
    "```python\n",
    "rul_estimator.fit(inputs=data_channels)\n",
    "job_name = rul_estimator._current_job_name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-16 09:12:37 Starting - Starting the training job...\n",
      "2020-06-16 09:12:39 Starting - Launching requested ML instances......\n",
      "2020-06-16 09:13:47 Starting - Preparing the instances for training......\n",
      "2020-06-16 09:15:04 Downloading - Downloading input data\n",
      "2020-06-16 09:15:04 Training - Downloading the training image...\n",
      "2020-06-16 09:15:25 Training - Training image download completed. Training in progress.\u001b[34m2020-06-16 09:15:27,244 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:27,248 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:27,264 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch-size\":16,\"epoch\":200,\"hidden-size\":122,\"learning-rate\":0.0034711926221743473,\"num-layers\":3,\"sequence-length\":20}', 'SM_USER_ENTRY_POINT': 'nasa_rul_training.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_parameter_server_enabled\":true}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"train\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'nasa_rul_training', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-eu-west-1-123031033346/nasa-rul-lstm/code/nasa-rul-lstm-2020-06-16-09-12-37-314/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":16,\"epoch\":200,\"hidden-size\":122,\"learning-rate\":0.0034711926221743473,\"num-layers\":3,\"sequence-length\":20},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"nasa-rul-lstm-2020-06-16-09-12-37-314\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-123031033346/nasa-rul-lstm/code/nasa-rul-lstm-2020-06-16-09-12-37-314/source/sourcedir.tar.gz\",\"module_name\":\"nasa_rul_training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"nasa_rul_training.py\"}', 'SM_USER_ARGS': '[\"--batch-size\",\"16\",\"--epoch\",\"200\",\"--hidden-size\",\"122\",\"--learning-rate\",\"0.0034711926221743473\",\"--num-layers\",\"3\",\"--sequence-length\",\"20\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_HP_NUM-LAYERS': '3', 'SM_HP_SEQUENCE-LENGTH': '20', 'SM_HP_EPOCH': '200', 'SM_HP_BATCH-SIZE': '16', 'SM_HP_LEARNING-RATE': '0.0034711926221743473', 'SM_HP_HIDDEN-SIZE': '122'}\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:28,698 sagemaker_mxnet_container.training INFO     Starting distributed training task\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:29,179 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:29,179 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:29,179 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:29,179 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpym7lci5z/module_dir\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\n",
      "    Running setup.py install for default-user-module-name: started\u001b[0m\n",
      "\u001b[34m    Running setup.py install for default-user-module-name: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:32,156 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:32,174 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:32,191 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-16 09:15:32,206 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"num-layers\": 3,\n",
      "        \"sequence-length\": 20,\n",
      "        \"epoch\": 200,\n",
      "        \"batch-size\": 16,\n",
      "        \"learning-rate\": 0.0034711926221743473,\n",
      "        \"hidden-size\": 122\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"nasa-rul-lstm-2020-06-16-09-12-37-314\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-123031033346/nasa-rul-lstm/code/nasa-rul-lstm-2020-06-16-09-12-37-314/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"nasa_rul_training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"nasa_rul_training.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":16,\"epoch\":200,\"hidden-size\":122,\"learning-rate\":0.0034711926221743473,\"num-layers\":3,\"sequence-length\":20}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=nasa_rul_training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=nasa_rul_training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-123031033346/nasa-rul-lstm/code/nasa-rul-lstm-2020-06-16-09-12-37-314/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":16,\"epoch\":200,\"hidden-size\":122,\"learning-rate\":0.0034711926221743473,\"num-layers\":3,\"sequence-length\":20},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"nasa-rul-lstm-2020-06-16-09-12-37-314\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-123031033346/nasa-rul-lstm/code/nasa-rul-lstm-2020-06-16-09-12-37-314/source/sourcedir.tar.gz\",\"module_name\":\"nasa_rul_training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"nasa_rul_training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"16\",\"--epoch\",\"200\",\"--hidden-size\",\"122\",\"--learning-rate\",\"0.0034711926221743473\",\"--num-layers\",\"3\",\"--sequence-length\",\"20\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-LAYERS=3\u001b[0m\n",
      "\u001b[34mSM_HP_SEQUENCE-LENGTH=20\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=200\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.0034711926221743473\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN-SIZE=122\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 nasa_rul_training.py --batch-size 16 --epoch 200 --hidden-size 122 --learning-rate 0.0034711926221743473 --num-layers 3 --sequence-length 20\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Loading data\u001b[0m\n",
      "\u001b[34mPath:  /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Sequences: (18631, 20, 17)\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Labels: (18631, 1)\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Initializing network\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Training start\u001b[0m\n",
      "\u001b[34mTraining begin: using optimizer Adam with current learning rate 0.0035 \u001b[0m\n",
      "\u001b[34mTrain for 200 epochs.\u001b[0m\n",
      "\u001b[34m[Epoch 0] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34m[2020-06-16 09:15:34.140 ip-10-0-145-204.eu-west-1.compute.internal:102 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-06-16 09:15:34.141 ip-10-0-145-204.eu-west-1.compute.internal:102 INFO hook.py:170] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-06-16 09:15:34.141 ip-10-0-145-204.eu-west-1.compute.internal:102 INFO hook.py:215] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-06-16 09:15:34.174 ip-10-0-145-204.eu-west-1.compute.internal:102 INFO hook.py:351] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-06-16 09:15:34.190 ip-10-0-145-204.eu-west-1.compute.internal:102 INFO hook.py:226] Registering hook for block l2loss0\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.31775838136672974,Timestamp=1592298934.2882297,IterationNumber=0)\u001b[0m\n",
      "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010305759496986866,Timestamp=1592298946.8851259,IterationNumber=500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.01635298691689968,Timestamp=1592298959.2219937,IterationNumber=1000)\u001b[0m\n",
      "\u001b[34m[Epoch 0] Finished in 29.369s, training rmse: 0.1764, training loss: 0.0184\u001b[0m\n",
      "\u001b[34m[Epoch 1] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.013147236779332161,Timestamp=1592298972.3831658,IterationNumber=1500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008567068725824356,Timestamp=1592298984.5995893,IterationNumber=2000)\u001b[0m\n",
      "\u001b[34m[Epoch 1] Finished in 29.423s, training rmse: 0.1402, training loss: 0.0102\u001b[0m\n",
      "\u001b[34m[Epoch 2] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007245349697768688,Timestamp=1592298996.9464114,IterationNumber=2500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0069526913575828075,Timestamp=1592299009.3864152,IterationNumber=3000)\u001b[0m\n",
      "\u001b[34m[Epoch 2] Finished in 28.798s, training rmse: 0.1346, training loss: 0.0094\u001b[0m\n",
      "\u001b[34m[Epoch 3] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006634336896240711,Timestamp=1592299021.67741,IterationNumber=3500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009680449962615967,Timestamp=1592299034.3944778,IterationNumber=4000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.015309061855077744,Timestamp=1592299046.7433908,IterationNumber=4500)\u001b[0m\n",
      "\u001b[34m[Epoch 3] Finished in 29.209s, training rmse: 0.1304, training loss: 0.0089\u001b[0m\n",
      "\u001b[34m[Epoch 4] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.01026990171521902,Timestamp=1592299059.3370903,IterationNumber=5000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005603696219623089,Timestamp=1592299071.8096483,IterationNumber=5500)\u001b[0m\n",
      "\u001b[34m[Epoch 4] Finished in 29.291s, training rmse: 0.1290, training loss: 0.0087\u001b[0m\n",
      "\u001b[34m[Epoch 5] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006490055471658707,Timestamp=1592299084.4886756,IterationNumber=6000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0066587552428245544,Timestamp=1592299097.079801,IterationNumber=6500)\u001b[0m\n",
      "\u001b[34m[Epoch 5] Finished in 29.241s, training rmse: 0.1270, training loss: 0.0084\u001b[0m\n",
      "\u001b[34m[Epoch 6] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0085136154666543,Timestamp=1592299109.5534286,IterationNumber=7000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007619358599185944,Timestamp=1592299122.1338797,IterationNumber=7500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007170696742832661,Timestamp=1592299134.5957208,IterationNumber=8000)\u001b[0m\n",
      "\u001b[34m[Epoch 6] Finished in 29.136s, training rmse: 0.1267, training loss: 0.0084\u001b[0m\n",
      "\u001b[34m[Epoch 7] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.014968425035476685,Timestamp=1592299147.110602,IterationNumber=8500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006073986180126667,Timestamp=1592299159.5449805,IterationNumber=9000)\u001b[0m\n",
      "\u001b[34m[Epoch 7] Finished in 29.175s, training rmse: 0.1264, training loss: 0.0083\u001b[0m\n",
      "\u001b[34m[Epoch 8] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009477229788899422,Timestamp=1592299172.0695646,IterationNumber=9500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.015541015192866325,Timestamp=1592299184.4737754,IterationNumber=10000)\u001b[0m\n",
      "\u001b[34m[Epoch 8] Finished in 28.851s, training rmse: 0.1256, training loss: 0.0082\u001b[0m\n",
      "\u001b[34m[Epoch 9] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004889623261988163,Timestamp=1592299196.8397973,IterationNumber=10500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005001063458621502,Timestamp=1592299209.2952754,IterationNumber=11000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00733797624707222,Timestamp=1592299221.6815963,IterationNumber=11500)\u001b[0m\n",
      "\u001b[34m[Epoch 9] Finished in 29.009s, training rmse: 0.1241, training loss: 0.0080\u001b[0m\n",
      "\u001b[34m[Epoch 10] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.01252681389451027,Timestamp=1592299234.15553,IterationNumber=12000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.01580788753926754,Timestamp=1592299246.6622272,IterationNumber=12500)\u001b[0m\n",
      "\u001b[34m[Epoch 10] Finished in 29.037s, training rmse: 0.1251, training loss: 0.0081\u001b[0m\n",
      "\u001b[34m[Epoch 11] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007822588086128235,Timestamp=1592299259.1813228,IterationNumber=13000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010311545804142952,Timestamp=1592299271.841193,IterationNumber=13500)\u001b[0m\n",
      "\u001b[34m[Epoch 11] Finished in 29.314s, training rmse: 0.1249, training loss: 0.0081\u001b[0m\n",
      "\u001b[34m[Epoch 12] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.011304138228297234,Timestamp=1592299284.3055017,IterationNumber=14000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006710410118103027,Timestamp=1592299296.9161928,IterationNumber=14500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003808452747762203,Timestamp=1592299309.4906068,IterationNumber=15000)\u001b[0m\n",
      "\u001b[34m[Epoch 12] Finished in 29.366s, training rmse: 0.1233, training loss: 0.0079\u001b[0m\n",
      "\u001b[34m[Epoch 13] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00773191824555397,Timestamp=1592299322.2034674,IterationNumber=15500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00592779740691185,Timestamp=1592299334.8087752,IterationNumber=16000)\u001b[0m\n",
      "\u001b[34m[Epoch 13] Finished in 29.449s, training rmse: 0.1237, training loss: 0.0080\u001b[0m\n",
      "\u001b[34m[Epoch 14] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007633186411112547,Timestamp=1592299347.5474067,IterationNumber=16500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010924672707915306,Timestamp=1592299360.1935947,IterationNumber=17000)\u001b[0m\n",
      "\u001b[34m[Epoch 14] Finished in 29.759s, training rmse: 0.1233, training loss: 0.0079\u001b[0m\n",
      "\u001b[34m[Epoch 15] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009275663644075394,Timestamp=1592299373.0209084,IterationNumber=17500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0070549966767430305,Timestamp=1592299385.6043236,IterationNumber=18000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004367142450064421,Timestamp=1592299398.2818162,IterationNumber=18500)\u001b[0m\n",
      "\u001b[34m[Epoch 15] Finished in 29.434s, training rmse: 0.1246, training loss: 0.0081\u001b[0m\n",
      "\u001b[34m[Epoch 16] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010896635241806507,Timestamp=1592299410.8795533,IterationNumber=19000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006650148890912533,Timestamp=1592299423.6251495,IterationNumber=19500)\u001b[0m\n",
      "\u001b[34m[Epoch 16] Finished in 29.901s, training rmse: 0.1235, training loss: 0.0079\u001b[0m\n",
      "\u001b[34m[Epoch 17] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008236262015998363,Timestamp=1592299437.176096,IterationNumber=20000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009517405182123184,Timestamp=1592299450.5992117,IterationNumber=20500)\u001b[0m\n",
      "\u001b[34m[Epoch 17] Finished in 30.770s, training rmse: 0.1229, training loss: 0.0079\u001b[0m\n",
      "\u001b[34m[Epoch 18] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008377954363822937,Timestamp=1592299463.3233547,IterationNumber=21000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005057253874838352,Timestamp=1592299475.898891,IterationNumber=21500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008218837901949883,Timestamp=1592299488.4376047,IterationNumber=22000)\u001b[0m\n",
      "\u001b[34m[Epoch 18] Finished in 29.340s, training rmse: 0.1231, training loss: 0.0079\u001b[0m\n",
      "\u001b[34m[Epoch 19] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.013519253581762314,Timestamp=1592299501.0832484,IterationNumber=22500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005893342196941376,Timestamp=1592299513.8045826,IterationNumber=23000)\u001b[0m\n",
      "\u001b[34m[Epoch 19] Finished in 29.562s, training rmse: 0.1227, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 20] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005468148738145828,Timestamp=1592299526.4195433,IterationNumber=23500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003769836388528347,Timestamp=1592299539.0049076,IterationNumber=24000)\u001b[0m\n",
      "\u001b[34m[Epoch 20] Finished in 29.432s, training rmse: 0.1227, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 21] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.014020727016031742,Timestamp=1592299551.7683496,IterationNumber=24500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.01171397790312767,Timestamp=1592299564.504163,IterationNumber=25000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008209804072976112,Timestamp=1592299577.3727105,IterationNumber=25500)\u001b[0m\n",
      "\u001b[34m[Epoch 21] Finished in 29.882s, training rmse: 0.1224, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 22] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008481577970087528,Timestamp=1592299590.2126565,IterationNumber=26000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005160468630492687,Timestamp=1592299602.933086,IterationNumber=26500)\u001b[0m\n",
      "\u001b[34m[Epoch 22] Finished in 29.734s, training rmse: 0.1227, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 23] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008313389495015144,Timestamp=1592299615.7257843,IterationNumber=27000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007702612783759832,Timestamp=1592299628.5370061,IterationNumber=27500)\u001b[0m\n",
      "\u001b[34m[Epoch 23] Finished in 29.887s, training rmse: 0.1221, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 24] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006198170129209757,Timestamp=1592299641.3404663,IterationNumber=28000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0028266706503927708,Timestamp=1592299654.0641298,IterationNumber=28500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007248621433973312,Timestamp=1592299666.8613706,IterationNumber=29000)\u001b[0m\n",
      "\u001b[34m[Epoch 24] Finished in 29.723s, training rmse: 0.1223, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 25] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009457548148930073,Timestamp=1592299679.6348026,IterationNumber=29500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006623770110309124,Timestamp=1592299692.4182677,IterationNumber=30000)\u001b[0m\n",
      "\u001b[34m[Epoch 25] Finished in 29.801s, training rmse: 0.1222, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 26] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00453963503241539,Timestamp=1592299705.2177706,IterationNumber=30500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006158123724162579,Timestamp=1592299717.906999,IterationNumber=31000)\u001b[0m\n",
      "\u001b[34m[Epoch 26] Finished in 29.969s, training rmse: 0.1220, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 27] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005883183795958757,Timestamp=1592299731.014832,IterationNumber=31500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005983503069728613,Timestamp=1592299743.929253,IterationNumber=32000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006820973940193653,Timestamp=1592299756.9212437,IterationNumber=32500)\u001b[0m\n",
      "\u001b[34m[Epoch 27] Finished in 30.149s, training rmse: 0.1225, training loss: 0.0078\u001b[0m\n",
      "\u001b[34m[Epoch 28] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008044744841754436,Timestamp=1592299769.7708461,IterationNumber=33000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004176049027591944,Timestamp=1592299782.556771,IterationNumber=33500)\u001b[0m\n",
      "\u001b[34m[Epoch 28] Finished in 29.906s, training rmse: 0.1217, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 29] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006226181052625179,Timestamp=1592299795.3924217,IterationNumber=34000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010744309052824974,Timestamp=1592299808.2099955,IterationNumber=34500)\u001b[0m\n",
      "\u001b[34m[Epoch 29] Finished in 29.954s, training rmse: 0.1218, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 30] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007596306968480349,Timestamp=1592299821.1002119,IterationNumber=35000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009368786588311195,Timestamp=1592299833.8613284,IterationNumber=35500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007973292842507362,Timestamp=1592299846.8690965,IterationNumber=36000)\u001b[0m\n",
      "\u001b[34m[Epoch 30] Finished in 29.974s, training rmse: 0.1211, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 31] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.011454587802290916,Timestamp=1592299859.8310406,IterationNumber=36500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0033481521531939507,Timestamp=1592299872.838212,IterationNumber=37000)\u001b[0m\n",
      "\u001b[34m[Epoch 31] Finished in 30.355s, training rmse: 0.1212, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 32] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006007392890751362,Timestamp=1592299885.8912244,IterationNumber=37500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0035314629785716534,Timestamp=1592299898.879701,IterationNumber=38000)\u001b[0m\n",
      "\u001b[34m[Epoch 32] Finished in 30.261s, training rmse: 0.1211, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 33] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009541889652609825,Timestamp=1592299911.9054158,IterationNumber=38500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005614419933408499,Timestamp=1592299925.0040128,IterationNumber=39000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003604734782129526,Timestamp=1592299938.116746,IterationNumber=39500)\u001b[0m\n",
      "\u001b[34m[Epoch 33] Finished in 30.526s, training rmse: 0.1210, training loss: 0.0076\u001b[0m\n",
      "\u001b[34m[Epoch 34] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007446441799402237,Timestamp=1592299951.208673,IterationNumber=40000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005601853597909212,Timestamp=1592299964.2337158,IterationNumber=40500)\u001b[0m\n",
      "\u001b[34m[Epoch 34] Finished in 30.514s, training rmse: 0.1217, training loss: 0.0077\u001b[0m\n",
      "\u001b[34m[Epoch 35] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.012350027449429035,Timestamp=1592299977.3762813,IterationNumber=41000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008324770256876945,Timestamp=1592299990.566932,IterationNumber=41500)\u001b[0m\n",
      "\u001b[34m[Epoch 35] Finished in 30.607s, training rmse: 0.1210, training loss: 0.0076\u001b[0m\n",
      "\u001b[34m[Epoch 36] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0052942801266908646,Timestamp=1592300003.6445177,IterationNumber=42000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.011760028079152107,Timestamp=1592300016.8051708,IterationNumber=42500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007633705623447895,Timestamp=1592300029.9524398,IterationNumber=43000)\u001b[0m\n",
      "\u001b[34m[Epoch 36] Finished in 30.615s, training rmse: 0.1205, training loss: 0.0076\u001b[0m\n",
      "\u001b[34m[Epoch 37] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008291903883218765,Timestamp=1592300043.128573,IterationNumber=43500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.015161463059484959,Timestamp=1592300056.4032001,IterationNumber=44000)\u001b[0m\n",
      "\u001b[34m[Epoch 37] Finished in 30.801s, training rmse: 0.1204, training loss: 0.0076\u001b[0m\n",
      "\u001b[34m[Epoch 38] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0039033833891153336,Timestamp=1592300069.609119,IterationNumber=44500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006449510809034109,Timestamp=1592300082.6840653,IterationNumber=45000)\u001b[0m\n",
      "\u001b[34m[Epoch 38] Finished in 30.639s, training rmse: 0.1205, training loss: 0.0076\u001b[0m\n",
      "\u001b[34m[Epoch 39] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0034148632548749447,Timestamp=1592300095.8046405,IterationNumber=45500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0044267987832427025,Timestamp=1592300108.9322355,IterationNumber=46000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005459977313876152,Timestamp=1592300122.1431916,IterationNumber=46500)\u001b[0m\n",
      "\u001b[34m[Epoch 39] Finished in 30.633s, training rmse: 0.1200, training loss: 0.0075\u001b[0m\n",
      "\u001b[34m[Epoch 40] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.013730980455875397,Timestamp=1592300135.3347652,IterationNumber=47000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005475467070937157,Timestamp=1592300148.7248833,IterationNumber=47500)\u001b[0m\n",
      "\u001b[34m[Epoch 40] Finished in 31.102s, training rmse: 0.1199, training loss: 0.0075\u001b[0m\n",
      "\u001b[34m[Epoch 41] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009668702259659767,Timestamp=1592300162.1724253,IterationNumber=48000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.011893771588802338,Timestamp=1592300175.663534,IterationNumber=48500)\u001b[0m\n",
      "\u001b[34m[Epoch 41] Finished in 31.495s, training rmse: 0.1197, training loss: 0.0075\u001b[0m\n",
      "\u001b[34m[Epoch 42] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0048081036657094955,Timestamp=1592300189.2062845,IterationNumber=49000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005348945967853069,Timestamp=1592300202.6695378,IterationNumber=49500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004101488273590803,Timestamp=1592300216.1418219,IterationNumber=50000)\u001b[0m\n",
      "\u001b[34m[Epoch 42] Finished in 31.373s, training rmse: 0.1197, training loss: 0.0075\u001b[0m\n",
      "\u001b[34m[Epoch 43] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.013391406275331974,Timestamp=1592300229.677504,IterationNumber=50500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004283408168703318,Timestamp=1592300243.1599452,IterationNumber=51000)\u001b[0m\n",
      "\u001b[34m[Epoch 43] Finished in 31.429s, training rmse: 0.1194, training loss: 0.0074\u001b[0m\n",
      "\u001b[34m[Epoch 44] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007267061620950699,Timestamp=1592300256.610034,IterationNumber=51500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.014066925272345543,Timestamp=1592300270.0433962,IterationNumber=52000)\u001b[0m\n",
      "\u001b[34m[Epoch 44] Finished in 31.399s, training rmse: 0.1192, training loss: 0.0074\u001b[0m\n",
      "\u001b[34m[Epoch 45] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006177471484988928,Timestamp=1592300283.6155293,IterationNumber=52500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005181046202778816,Timestamp=1592300297.1236193,IterationNumber=53000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005403490737080574,Timestamp=1592300310.5057127,IterationNumber=53500)\u001b[0m\n",
      "\u001b[34m[Epoch 45] Finished in 31.421s, training rmse: 0.1190, training loss: 0.0074\u001b[0m\n",
      "\u001b[34m[Epoch 46] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.011857730336487293,Timestamp=1592300324.1169784,IterationNumber=54000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.012805829755961895,Timestamp=1592300337.7530599,IterationNumber=54500)\u001b[0m\n",
      "\u001b[34m[Epoch 46] Finished in 31.673s, training rmse: 0.1191, training loss: 0.0074\u001b[0m\n",
      "\u001b[34m[Epoch 47] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004901687614619732,Timestamp=1592300351.2328098,IterationNumber=55000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007457799278199673,Timestamp=1592300364.7472458,IterationNumber=55500)\u001b[0m\n",
      "\u001b[34m[Epoch 47] Finished in 31.448s, training rmse: 0.1186, training loss: 0.0073\u001b[0m\n",
      "\u001b[34m[Epoch 48] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007786313071846962,Timestamp=1592300378.313479,IterationNumber=56000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001599648967385292,Timestamp=1592300391.8094058,IterationNumber=56500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006474814377725124,Timestamp=1592300405.2834184,IterationNumber=57000)\u001b[0m\n",
      "\u001b[34m[Epoch 48] Finished in 31.477s, training rmse: 0.1185, training loss: 0.0073\u001b[0m\n",
      "\u001b[34m[Epoch 49] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0034096301533281803,Timestamp=1592300418.7252524,IterationNumber=57500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0036164666526019573,Timestamp=1592300432.105754,IterationNumber=58000)\u001b[0m\n",
      "\u001b[34m[Epoch 49] Finished in 31.235s, training rmse: 0.1178, training loss: 0.0072\u001b[0m\n",
      "\u001b[34m[Epoch 50] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004618939943611622,Timestamp=1592300445.5617456,IterationNumber=58500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004221105016767979,Timestamp=1592300459.1583676,IterationNumber=59000)\u001b[0m\n",
      "\u001b[34m[Epoch 50] Finished in 31.543s, training rmse: 0.1182, training loss: 0.0073\u001b[0m\n",
      "\u001b[34m[Epoch 51] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009648033417761326,Timestamp=1592300472.6163151,IterationNumber=59500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007693864870816469,Timestamp=1592300486.1777596,IterationNumber=60000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0057136910036206245,Timestamp=1592300499.691465,IterationNumber=60500)\u001b[0m\n",
      "\u001b[34m[Epoch 51] Finished in 31.482s, training rmse: 0.1172, training loss: 0.0072\u001b[0m\n",
      "\u001b[34m[Epoch 52] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0032740223687142134,Timestamp=1592300513.3518221,IterationNumber=61000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.011286387220025063,Timestamp=1592300526.95272,IterationNumber=61500)\u001b[0m\n",
      "\u001b[34m[Epoch 52] Finished in 31.716s, training rmse: 0.1166, training loss: 0.0071\u001b[0m\n",
      "\u001b[34m[Epoch 53] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009482759982347488,Timestamp=1592300540.7010324,IterationNumber=62000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005177633371204138,Timestamp=1592300554.2502503,IterationNumber=62500)\u001b[0m\n",
      "\u001b[34m[Epoch 53] Finished in 31.968s, training rmse: 0.1164, training loss: 0.0071\u001b[0m\n",
      "\u001b[34m[Epoch 54] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006759275682270527,Timestamp=1592300568.0352967,IterationNumber=63000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008812365122139454,Timestamp=1592300581.8819783,IterationNumber=63500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0028342828154563904,Timestamp=1592300595.6499844,IterationNumber=64000)\u001b[0m\n",
      "\u001b[34m[Epoch 54] Finished in 32.164s, training rmse: 0.1166, training loss: 0.0071\u001b[0m\n",
      "\u001b[34m[Epoch 55] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004726514220237732,Timestamp=1592300609.5299923,IterationNumber=64500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008870864287018776,Timestamp=1592300623.2765224,IterationNumber=65000)\u001b[0m\n",
      "\u001b[34m[Epoch 55] Finished in 32.314s, training rmse: 0.1162, training loss: 0.0070\u001b[0m\n",
      "\u001b[34m[Epoch 56] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007540618069469929,Timestamp=1592300637.2746491,IterationNumber=65500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004514260683208704,Timestamp=1592300651.2993767,IterationNumber=66000)\u001b[0m\n",
      "\u001b[34m[Epoch 56] Finished in 32.787s, training rmse: 0.1158, training loss: 0.0070\u001b[0m\n",
      "\u001b[34m[Epoch 57] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00913732685148716,Timestamp=1592300665.440791,IterationNumber=66500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006011433899402618,Timestamp=1592300679.7399106,IterationNumber=67000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0036064828746020794,Timestamp=1592300693.8018665,IterationNumber=67500)\u001b[0m\n",
      "\u001b[34m[Epoch 57] Finished in 32.991s, training rmse: 0.1158, training loss: 0.0070\u001b[0m\n",
      "\u001b[34m[Epoch 58] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007177957333624363,Timestamp=1592300707.9930556,IterationNumber=68000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0053691985085606575,Timestamp=1592300722.0869398,IterationNumber=68500)\u001b[0m\n",
      "\u001b[34m[Epoch 58] Finished in 32.904s, training rmse: 0.1151, training loss: 0.0069\u001b[0m\n",
      "\u001b[34m[Epoch 59] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007673040963709354,Timestamp=1592300736.1633906,IterationNumber=69000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.012852566316723824,Timestamp=1592300750.33038,IterationNumber=69500)\u001b[0m\n",
      "\u001b[34m[Epoch 59] Finished in 33.202s, training rmse: 0.1149, training loss: 0.0069\u001b[0m\n",
      "\u001b[34m[Epoch 60] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0054113660007715225,Timestamp=1592300764.7105815,IterationNumber=70000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00674925372004509,Timestamp=1592300778.941157,IterationNumber=70500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005381640512496233,Timestamp=1592300793.2825322,IterationNumber=71000)\u001b[0m\n",
      "\u001b[34m[Epoch 60] Finished in 33.242s, training rmse: 0.1145, training loss: 0.0068\u001b[0m\n",
      "\u001b[34m[Epoch 61] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.01002686657011509,Timestamp=1592300807.8192182,IterationNumber=71500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004352029412984848,Timestamp=1592300822.2997077,IterationNumber=72000)\u001b[0m\n",
      "\u001b[34m[Epoch 61] Finished in 33.778s, training rmse: 0.1143, training loss: 0.0068\u001b[0m\n",
      "\u001b[34m[Epoch 62] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0075617339462041855,Timestamp=1592300836.5815232,IterationNumber=72500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0068351165391504765,Timestamp=1592300850.9850338,IterationNumber=73000)\u001b[0m\n",
      "\u001b[34m[Epoch 62] Finished in 33.553s, training rmse: 0.1136, training loss: 0.0067\u001b[0m\n",
      "\u001b[34m[Epoch 63] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00623015221208334,Timestamp=1592300865.605394,IterationNumber=73500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004856673534959555,Timestamp=1592300879.9724386,IterationNumber=74000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.013145290315151215,Timestamp=1592300894.3571022,IterationNumber=74500)\u001b[0m\n",
      "\u001b[34m[Epoch 63] Finished in 33.589s, training rmse: 0.1139, training loss: 0.0068\u001b[0m\n",
      "\u001b[34m[Epoch 64] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0029654433019459248,Timestamp=1592300908.7903004,IterationNumber=75000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00940195843577385,Timestamp=1592300923.16443,IterationNumber=75500)\u001b[0m\n",
      "\u001b[34m[Epoch 64] Finished in 33.577s, training rmse: 0.1134, training loss: 0.0067\u001b[0m\n",
      "\u001b[34m[Epoch 65] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004800048656761646,Timestamp=1592300937.6633682,IterationNumber=76000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006004511844366789,Timestamp=1592300952.355691,IterationNumber=76500)\u001b[0m\n",
      "\u001b[34m[Epoch 65] Finished in 34.105s, training rmse: 0.1131, training loss: 0.0067\u001b[0m\n",
      "\u001b[34m[Epoch 66] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005525642074644566,Timestamp=1592300966.9161189,IterationNumber=77000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005623766221106052,Timestamp=1592300981.3127594,IterationNumber=77500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004732356406748295,Timestamp=1592300995.7070591,IterationNumber=78000)\u001b[0m\n",
      "\u001b[34m[Epoch 66] Finished in 33.579s, training rmse: 0.1129, training loss: 0.0067\u001b[0m\n",
      "\u001b[34m[Epoch 67] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008587098680436611,Timestamp=1592301010.1091416,IterationNumber=78500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0023082923144102097,Timestamp=1592301024.5064428,IterationNumber=79000)\u001b[0m\n",
      "\u001b[34m[Epoch 67] Finished in 33.489s, training rmse: 0.1121, training loss: 0.0066\u001b[0m\n",
      "\u001b[34m[Epoch 68] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008659424260258675,Timestamp=1592301038.8661392,IterationNumber=79500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0049314554780721664,Timestamp=1592301053.3701544,IterationNumber=80000)\u001b[0m\n",
      "\u001b[34m[Epoch 68] Finished in 33.845s, training rmse: 0.1117, training loss: 0.0065\u001b[0m\n",
      "\u001b[34m[Epoch 69] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004499356262385845,Timestamp=1592301068.0473177,IterationNumber=80500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009653320536017418,Timestamp=1592301082.6899762,IterationNumber=81000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006119154393672943,Timestamp=1592301097.1851707,IterationNumber=81500)\u001b[0m\n",
      "\u001b[34m[Epoch 69] Finished in 33.998s, training rmse: 0.1117, training loss: 0.0065\u001b[0m\n",
      "\u001b[34m[Epoch 70] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007294695824384689,Timestamp=1592301111.8478127,IterationNumber=82000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008132204413414001,Timestamp=1592301126.5410578,IterationNumber=82500)\u001b[0m\n",
      "\u001b[34m[Epoch 70] Finished in 34.224s, training rmse: 0.1111, training loss: 0.0064\u001b[0m\n",
      "\u001b[34m[Epoch 71] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008701881393790245,Timestamp=1592301141.2448032,IterationNumber=83000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010720796883106232,Timestamp=1592301155.9777825,IterationNumber=83500)\u001b[0m\n",
      "\u001b[34m[Epoch 71] Finished in 34.318s, training rmse: 0.1111, training loss: 0.0065\u001b[0m\n",
      "\u001b[34m[Epoch 72] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00507801678031683,Timestamp=1592301170.6899474,IterationNumber=84000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008528901264071465,Timestamp=1592301185.5715532,IterationNumber=84500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004572272300720215,Timestamp=1592301200.3085911,IterationNumber=85000)\u001b[0m\n",
      "\u001b[34m[Epoch 72] Finished in 34.582s, training rmse: 0.1106, training loss: 0.0064\u001b[0m\n",
      "\u001b[34m[Epoch 73] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0043864077888429165,Timestamp=1592301215.1519578,IterationNumber=85500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0036121425218880177,Timestamp=1592301229.9621453,IterationNumber=86000)\u001b[0m\n",
      "\u001b[34m[Epoch 73] Finished in 34.576s, training rmse: 0.1096, training loss: 0.0063\u001b[0m\n",
      "\u001b[34m[Epoch 74] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0077640460804104805,Timestamp=1592301245.1176178,IterationNumber=86500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0033009268809109926,Timestamp=1592301259.9544423,IterationNumber=87000)\u001b[0m\n",
      "\u001b[34m[Epoch 74] Finished in 34.812s, training rmse: 0.1093, training loss: 0.0063\u001b[0m\n",
      "\u001b[34m[Epoch 75] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004024864174425602,Timestamp=1592301274.892723,IterationNumber=87500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.009435532614588737,Timestamp=1592301289.7949302,IterationNumber=88000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004429536405950785,Timestamp=1592301304.5594156,IterationNumber=88500)\u001b[0m\n",
      "\u001b[34m[Epoch 75] Finished in 34.607s, training rmse: 0.1083, training loss: 0.0061\u001b[0m\n",
      "\u001b[34m[Epoch 76] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00971702765673399,Timestamp=1592301319.425423,IterationNumber=89000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002886038040742278,Timestamp=1592301334.2677715,IterationNumber=89500)\u001b[0m\n",
      "\u001b[34m[Epoch 76] Finished in 34.598s, training rmse: 0.1081, training loss: 0.0061\u001b[0m\n",
      "\u001b[34m[Epoch 77] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008419045247137547,Timestamp=1592301349.0401754,IterationNumber=90000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0061661116778850555,Timestamp=1592301363.9224477,IterationNumber=90500)\u001b[0m\n",
      "\u001b[34m[Epoch 77] Finished in 34.560s, training rmse: 0.1077, training loss: 0.0061\u001b[0m\n",
      "\u001b[34m[Epoch 78] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007231568451970816,Timestamp=1592301378.823171,IterationNumber=91000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008816825225949287,Timestamp=1592301393.8190415,IterationNumber=91500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0064251963049173355,Timestamp=1592301408.6937568,IterationNumber=92000)\u001b[0m\n",
      "\u001b[34m[Epoch 78] Finished in 34.887s, training rmse: 0.1066, training loss: 0.0060\u001b[0m\n",
      "\u001b[34m[Epoch 79] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004819256253540516,Timestamp=1592301423.749909,IterationNumber=92500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0068711647763848305,Timestamp=1592301438.766238,IterationNumber=93000)\u001b[0m\n",
      "\u001b[34m[Epoch 79] Finished in 35.120s, training rmse: 0.1062, training loss: 0.0059\u001b[0m\n",
      "\u001b[34m[Epoch 80] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004589515272527933,Timestamp=1592301453.9213583,IterationNumber=93500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0030207172967493534,Timestamp=1592301468.9004498,IterationNumber=94000)\u001b[0m\n",
      "\u001b[34m[Epoch 80] Finished in 35.172s, training rmse: 0.1051, training loss: 0.0058\u001b[0m\n",
      "\u001b[34m[Epoch 81] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007645411416888237,Timestamp=1592301484.2004523,IterationNumber=94500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00635438272729516,Timestamp=1592301499.2132516,IterationNumber=95000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004774357192218304,Timestamp=1592301514.4741995,IterationNumber=95500)\u001b[0m\n",
      "\u001b[34m[Epoch 81] Finished in 35.274s, training rmse: 0.1052, training loss: 0.0058\u001b[0m\n",
      "\u001b[34m[Epoch 82] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00926345307379961,Timestamp=1592301529.5746558,IterationNumber=96000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005305013619363308,Timestamp=1592301544.7509606,IterationNumber=96500)\u001b[0m\n",
      "\u001b[34m[Epoch 82] Finished in 35.265s, training rmse: 0.1044, training loss: 0.0057\u001b[0m\n",
      "\u001b[34m[Epoch 83] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.013230888172984123,Timestamp=1592301559.8417633,IterationNumber=97000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0035965940915048122,Timestamp=1592301575.193539,IterationNumber=97500)\u001b[0m\n",
      "\u001b[34m[Epoch 83] Finished in 35.548s, training rmse: 0.1039, training loss: 0.0057\u001b[0m\n",
      "\u001b[34m[Epoch 84] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006074205040931702,Timestamp=1592301590.4677799,IterationNumber=98000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005618528462946415,Timestamp=1592301605.7505453,IterationNumber=98500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006287533789873123,Timestamp=1592301620.8128524,IterationNumber=99000)\u001b[0m\n",
      "\u001b[34m[Epoch 84] Finished in 35.391s, training rmse: 0.1028, training loss: 0.0055\u001b[0m\n",
      "\u001b[34m[Epoch 85] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00413762079551816,Timestamp=1592301635.952126,IterationNumber=99500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008733409456908703,Timestamp=1592301650.917512,IterationNumber=100000)\u001b[0m\n",
      "\u001b[34m[Epoch 85] Finished in 35.154s, training rmse: 0.1017, training loss: 0.0054\u001b[0m\n",
      "\u001b[34m[Epoch 86] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005483001004904509,Timestamp=1592301666.0774221,IterationNumber=100500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002783662173897028,Timestamp=1592301681.1728723,IterationNumber=101000)\u001b[0m\n",
      "\u001b[34m[Epoch 86] Finished in 35.362s, training rmse: 0.1013, training loss: 0.0054\u001b[0m\n",
      "\u001b[34m[Epoch 87] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0071936375461518764,Timestamp=1592301696.5606794,IterationNumber=101500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.010434646159410477,Timestamp=1592301711.68859,IterationNumber=102000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00537157291546464,Timestamp=1592301727.1496768,IterationNumber=102500)\u001b[0m\n",
      "\u001b[34m[Epoch 87] Finished in 35.671s, training rmse: 0.1007, training loss: 0.0053\u001b[0m\n",
      "\u001b[34m[Epoch 88] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003333666129037738,Timestamp=1592301742.44844,IterationNumber=103000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004861408844590187,Timestamp=1592301757.7629545,IterationNumber=103500)\u001b[0m\n",
      "\u001b[34m[Epoch 88] Finished in 35.606s, training rmse: 0.1004, training loss: 0.0053\u001b[0m\n",
      "\u001b[34m[Epoch 89] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003780992701649666,Timestamp=1592301772.9971094,IterationNumber=104000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006621296983212233,Timestamp=1592301788.402794,IterationNumber=104500)\u001b[0m\n",
      "\u001b[34m[Epoch 89] Finished in 35.879s, training rmse: 0.0997, training loss: 0.0052\u001b[0m\n",
      "\u001b[34m[Epoch 90] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0029503200203180313,Timestamp=1592301803.7739723,IterationNumber=105000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0029808753170073032,Timestamp=1592301819.1140823,IterationNumber=105500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005645107477903366,Timestamp=1592301834.4773495,IterationNumber=106000)\u001b[0m\n",
      "\u001b[34m[Epoch 90] Finished in 35.721s, training rmse: 0.0979, training loss: 0.0050\u001b[0m\n",
      "\u001b[34m[Epoch 91] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004553510807454586,Timestamp=1592301850.0134978,IterationNumber=106500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006316205486655235,Timestamp=1592301865.2769816,IterationNumber=107000)\u001b[0m\n",
      "\u001b[34m[Epoch 91] Finished in 35.899s, training rmse: 0.0987, training loss: 0.0051\u001b[0m\n",
      "\u001b[34m[Epoch 92] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005038682371377945,Timestamp=1592301880.8149765,IterationNumber=107500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0036123250611126423,Timestamp=1592301896.1087573,IterationNumber=108000)\u001b[0m\n",
      "\u001b[34m[Epoch 92] Finished in 36.116s, training rmse: 0.0971, training loss: 0.0050\u001b[0m\n",
      "\u001b[34m[Epoch 93] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010253380751237273,Timestamp=1592301911.754595,IterationNumber=108500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0037560504861176014,Timestamp=1592301926.990058,IterationNumber=109000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005147357936948538,Timestamp=1592301942.2576065,IterationNumber=109500)\u001b[0m\n",
      "\u001b[34m[Epoch 93] Finished in 35.579s, training rmse: 0.0977, training loss: 0.0050\u001b[0m\n",
      "\u001b[34m[Epoch 94] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00398660684004426,Timestamp=1592301957.3990836,IterationNumber=110000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004218197427690029,Timestamp=1592301972.6375296,IterationNumber=110500)\u001b[0m\n",
      "\u001b[34m[Epoch 94] Finished in 35.514s, training rmse: 0.0957, training loss: 0.0048\u001b[0m\n",
      "\u001b[34m[Epoch 95] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008090018294751644,Timestamp=1592301988.1118746,IterationNumber=111000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004631433170288801,Timestamp=1592302003.5276551,IterationNumber=111500)\u001b[0m\n",
      "\u001b[34m[Epoch 95] Finished in 35.990s, training rmse: 0.0953, training loss: 0.0048\u001b[0m\n",
      "\u001b[34m[Epoch 96] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.008564243093132973,Timestamp=1592302019.1474557,IterationNumber=112000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0047419434413313866,Timestamp=1592302034.4812374,IterationNumber=112500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0045466348528862,Timestamp=1592302049.9650135,IterationNumber=113000)\u001b[0m\n",
      "\u001b[34m[Epoch 96] Finished in 36.064s, training rmse: 0.0951, training loss: 0.0048\u001b[0m\n",
      "\u001b[34m[Epoch 97] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00720506627112627,Timestamp=1592302065.3993301,IterationNumber=113500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004983979277312756,Timestamp=1592302081.0203476,IterationNumber=114000)\u001b[0m\n",
      "\u001b[34m[Epoch 97] Finished in 36.186s, training rmse: 0.0943, training loss: 0.0047\u001b[0m\n",
      "\u001b[34m[Epoch 98] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005350199993699789,Timestamp=1592302096.4786532,IterationNumber=114500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0031461298931390047,Timestamp=1592302112.1192143,IterationNumber=115000)\u001b[0m\n",
      "\u001b[34m[Epoch 98] Finished in 36.149s, training rmse: 0.0939, training loss: 0.0047\u001b[0m\n",
      "\u001b[34m[Epoch 99] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.007393990643322468,Timestamp=1592302127.5515218,IterationNumber=115500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0030581618193536997,Timestamp=1592302143.0243456,IterationNumber=116000)\u001b[0m\n",
      "\u001b[34m[Epoch 99] Finished in 36.013s, training rmse: 0.0929, training loss: 0.0045\u001b[0m\n",
      "\u001b[34m[Epoch 100] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.005207168869674206,Timestamp=1592302158.4977577,IterationNumber=116500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006762154866009951,Timestamp=1592302174.053238,IterationNumber=117000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0031112385913729668,Timestamp=1592302189.5383947,IterationNumber=117500)\u001b[0m\n",
      "\u001b[34m[Epoch 100] Finished in 36.176s, training rmse: 0.0917, training loss: 0.0044\u001b[0m\n",
      "\u001b[34m[Epoch 101] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002656177617609501,Timestamp=1592302205.1145964,IterationNumber=118000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004038238897919655,Timestamp=1592302220.5459518,IterationNumber=118500)\u001b[0m\n",
      "\u001b[34m[Epoch 101] Finished in 36.163s, training rmse: 0.0909, training loss: 0.0043\u001b[0m\n",
      "\u001b[34m[Epoch 102] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0021335044875741005,Timestamp=1592302236.0756583,IterationNumber=119000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003766037058085203,Timestamp=1592302251.4189434,IterationNumber=119500)\u001b[0m\n",
      "\u001b[34m[Epoch 102] Finished in 35.941s, training rmse: 0.0916, training loss: 0.0044\u001b[0m\n",
      "\u001b[34m[Epoch 103] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0032374102156609297,Timestamp=1592302266.9278643,IterationNumber=120000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004644426982849836,Timestamp=1592302282.382492,IterationNumber=120500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002665570005774498,Timestamp=1592302298.1049085,IterationNumber=121000)\u001b[0m\n",
      "\u001b[34m[Epoch 103] Finished in 36.328s, training rmse: 0.0903, training loss: 0.0043\u001b[0m\n",
      "\u001b[34m[Epoch 104] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0038122045807540417,Timestamp=1592302313.6594262,IterationNumber=121500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003659355454146862,Timestamp=1592302329.3993254,IterationNumber=122000)\u001b[0m\n",
      "\u001b[34m[Epoch 104] Finished in 36.432s, training rmse: 0.0891, training loss: 0.0042\u001b[0m\n",
      "\u001b[34m[Epoch 105] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002932401141151786,Timestamp=1592302345.059135,IterationNumber=122500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003061051946133375,Timestamp=1592302360.8552291,IterationNumber=123000)\u001b[0m\n",
      "\u001b[34m[Epoch 105] Finished in 36.785s, training rmse: 0.0888, training loss: 0.0041\u001b[0m\n",
      "\u001b[34m[Epoch 106] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0038490891456604004,Timestamp=1592302376.6375096,IterationNumber=123500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001970913726836443,Timestamp=1592302392.7139437,IterationNumber=124000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006125910207629204,Timestamp=1592302408.5548863,IterationNumber=124500)\u001b[0m\n",
      "\u001b[34m[Epoch 106] Finished in 37.292s, training rmse: 0.0883, training loss: 0.0041\u001b[0m\n",
      "\u001b[34m[Epoch 107] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0018793318886309862,Timestamp=1592302424.5541945,IterationNumber=125000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012708501890301704,Timestamp=1592302440.5669553,IterationNumber=125500)\u001b[0m\n",
      "\u001b[34m[Epoch 107] Finished in 37.258s, training rmse: 0.0879, training loss: 0.0041\u001b[0m\n",
      "\u001b[34m[Epoch 108] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008032963378354907,Timestamp=1592302456.6881025,IterationNumber=126000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006038777995854616,Timestamp=1592302472.813231,IterationNumber=126500)\u001b[0m\n",
      "\u001b[34m[Epoch 108] Finished in 37.542s, training rmse: 0.0870, training loss: 0.0040\u001b[0m\n",
      "\u001b[34m[Epoch 109] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0021336169447749853,Timestamp=1592302488.8797145,IterationNumber=127000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003464141394942999,Timestamp=1592302505.4936848,IterationNumber=127500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006358001846820116,Timestamp=1592302521.8432212,IterationNumber=128000)\u001b[0m\n",
      "\u001b[34m[Epoch 109] Finished in 38.318s, training rmse: 0.0859, training loss: 0.0039\u001b[0m\n",
      "\u001b[34m[Epoch 110] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002557605504989624,Timestamp=1592302538.333811,IterationNumber=128500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0021186047233641148,Timestamp=1592302554.7547855,IterationNumber=129000)\u001b[0m\n",
      "\u001b[34m[Epoch 110] Finished in 38.493s, training rmse: 0.0848, training loss: 0.0038\u001b[0m\n",
      "\u001b[34m[Epoch 111] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00501303281635046,Timestamp=1592302571.4418027,IterationNumber=129500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0033881370909512043,Timestamp=1592302588.3217556,IterationNumber=130000)\u001b[0m\n",
      "\u001b[34m[Epoch 111] Finished in 39.349s, training rmse: 0.0842, training loss: 0.0037\u001b[0m\n",
      "\u001b[34m[Epoch 112] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002735663903877139,Timestamp=1592302605.2332146,IterationNumber=130500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002319970401003957,Timestamp=1592302622.883676,IterationNumber=131000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003316574264317751,Timestamp=1592302640.5330982,IterationNumber=131500)\u001b[0m\n",
      "\u001b[34m[Epoch 112] Finished in 41.083s, training rmse: 0.0830, training loss: 0.0036\u001b[0m\n",
      "\u001b[34m[Epoch 113] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0050222016870975494,Timestamp=1592302658.7133088,IterationNumber=132000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003353772684931755,Timestamp=1592302676.733141,IterationNumber=132500)\u001b[0m\n",
      "\u001b[34m[Epoch 113] Finished in 42.523s, training rmse: 0.0822, training loss: 0.0036\u001b[0m\n",
      "\u001b[34m[Epoch 114] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0024493958335369825,Timestamp=1592302695.49698,IterationNumber=133000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004098163917660713,Timestamp=1592302714.4550836,IterationNumber=133500)\u001b[0m\n",
      "\u001b[34m[Epoch 114] Finished in 44.122s, training rmse: 0.0815, training loss: 0.0035\u001b[0m\n",
      "\u001b[34m[Epoch 115] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.006337691098451614,Timestamp=1592302733.2626674,IterationNumber=134000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003742752131074667,Timestamp=1592302752.8731747,IterationNumber=134500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014354658778756857,Timestamp=1592302772.5254788,IterationNumber=135000)\u001b[0m\n",
      "\u001b[34m[Epoch 115] Finished in 45.844s, training rmse: 0.0812, training loss: 0.0035\u001b[0m\n",
      "\u001b[34m[Epoch 116] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002576539060100913,Timestamp=1592302792.737528,IterationNumber=135500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002830939833074808,Timestamp=1592302813.0844748,IterationNumber=136000)\u001b[0m\n",
      "\u001b[34m[Epoch 116] Finished in 47.326s, training rmse: 0.0803, training loss: 0.0034\u001b[0m\n",
      "\u001b[34m[Epoch 117] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004132635425776243,Timestamp=1592302833.6323996,IterationNumber=136500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002094447845593095,Timestamp=1592302854.4367313,IterationNumber=137000)\u001b[0m\n",
      "\u001b[34m[Epoch 117] Finished in 48.528s, training rmse: 0.0794, training loss: 0.0033\u001b[0m\n",
      "\u001b[34m[Epoch 118] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014967067399993539,Timestamp=1592302875.3029237,IterationNumber=137500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0021815430372953415,Timestamp=1592302896.8495567,IterationNumber=138000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001887923339381814,Timestamp=1592302918.379129,IterationNumber=138500)\u001b[0m\n",
      "\u001b[34m[Epoch 118] Finished in 50.205s, training rmse: 0.0796, training loss: 0.0033\u001b[0m\n",
      "\u001b[34m[Epoch 119] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0028938674367964268,Timestamp=1592302940.1605155,IterationNumber=139000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017086997395381331,Timestamp=1592302962.2596204,IterationNumber=139500)\u001b[0m\n",
      "\u001b[34m[Epoch 119] Finished in 51.278s, training rmse: 0.0779, training loss: 0.0032\u001b[0m\n",
      "\u001b[34m[Epoch 120] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002462781500071287,Timestamp=1592302984.429893,IterationNumber=140000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0071965670213103294,Timestamp=1592303006.3963134,IterationNumber=140500)\u001b[0m\n",
      "\u001b[34m[Epoch 120] Finished in 51.671s, training rmse: 0.0769, training loss: 0.0031\u001b[0m\n",
      "\u001b[34m[Epoch 121] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0024335351772606373,Timestamp=1592303028.7409437,IterationNumber=141000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0036667692475020885,Timestamp=1592303051.2043774,IterationNumber=141500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004983667749911547,Timestamp=1592303073.7265115,IterationNumber=142000)\u001b[0m\n",
      "\u001b[34m[Epoch 121] Finished in 52.446s, training rmse: 0.0758, training loss: 0.0030\u001b[0m\n",
      "\u001b[34m[Epoch 122] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002360748127102852,Timestamp=1592303096.2963815,IterationNumber=142500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0023325318470597267,Timestamp=1592303119.187333,IterationNumber=143000)\u001b[0m\n",
      "\u001b[34m[Epoch 122] Finished in 52.891s, training rmse: 0.0746, training loss: 0.0030\u001b[0m\n",
      "\u001b[34m[Epoch 123] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0018983558984473348,Timestamp=1592303141.795,IterationNumber=143500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002051004208624363,Timestamp=1592303164.3792422,IterationNumber=144000)\u001b[0m\n",
      "\u001b[34m[Epoch 123] Finished in 52.700s, training rmse: 0.0741, training loss: 0.0029\u001b[0m\n",
      "\u001b[34m[Epoch 124] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014215002302080393,Timestamp=1592303187.0677438,IterationNumber=144500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001191894058138132,Timestamp=1592303209.9826698,IterationNumber=145000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0019632827024906874,Timestamp=1592303233.0213492,IterationNumber=145500)\u001b[0m\n",
      "\u001b[34m[Epoch 124] Finished in 53.525s, training rmse: 0.0736, training loss: 0.0029\u001b[0m\n",
      "\u001b[34m[Epoch 125] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0025060130283236504,Timestamp=1592303256.0836763,IterationNumber=146000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0016912161372601986,Timestamp=1592303279.1795356,IterationNumber=146500)\u001b[0m\n",
      "\u001b[34m[Epoch 125] Finished in 53.948s, training rmse: 0.0730, training loss: 0.0028\u001b[0m\n",
      "\u001b[34m[Epoch 126] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0019322845619171858,Timestamp=1592303302.376335,IterationNumber=147000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003781259758397937,Timestamp=1592303325.6319685,IterationNumber=147500)\u001b[0m\n",
      "\u001b[34m[Epoch 126] Finished in 54.323s, training rmse: 0.0725, training loss: 0.0028\u001b[0m\n",
      "\u001b[34m[Epoch 127] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0019493806175887585,Timestamp=1592303349.0590475,IterationNumber=148000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002190443454310298,Timestamp=1592303372.3228416,IterationNumber=148500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0025620893575251102,Timestamp=1592303395.5928507,IterationNumber=149000)\u001b[0m\n",
      "\u001b[34m[Epoch 127] Finished in 54.222s, training rmse: 0.0713, training loss: 0.0027\u001b[0m\n",
      "\u001b[34m[Epoch 128] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004540946334600449,Timestamp=1592303419.1722639,IterationNumber=149500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0035454989410936832,Timestamp=1592303442.402512,IterationNumber=150000)\u001b[0m\n",
      "\u001b[34m[Epoch 128] Finished in 54.356s, training rmse: 0.0699, training loss: 0.0026\u001b[0m\n",
      "\u001b[34m[Epoch 129] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011404792312532663,Timestamp=1592303465.5792027,IterationNumber=150500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00254280143417418,Timestamp=1592303488.8458843,IterationNumber=151000)\u001b[0m\n",
      "\u001b[34m[Epoch 129] Finished in 54.467s, training rmse: 0.0699, training loss: 0.0026\u001b[0m\n",
      "\u001b[34m[Epoch 130] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002549645956605673,Timestamp=1592303512.3473861,IterationNumber=151500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0013105111429467797,Timestamp=1592303535.9887493,IterationNumber=152000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0034067181404680014,Timestamp=1592303559.698789,IterationNumber=152500)\u001b[0m\n",
      "\u001b[34m[Epoch 130] Finished in 55.126s, training rmse: 0.0685, training loss: 0.0025\u001b[0m\n",
      "\u001b[34m[Epoch 131] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004768345970660448,Timestamp=1592303583.573276,IterationNumber=153000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017338956240564585,Timestamp=1592303607.2175844,IterationNumber=153500)\u001b[0m\n",
      "\u001b[34m[Epoch 131] Finished in 55.329s, training rmse: 0.0680, training loss: 0.0024\u001b[0m\n",
      "\u001b[34m[Epoch 132] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.003326657461002469,Timestamp=1592303630.8941717,IterationNumber=154000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0030406988225877285,Timestamp=1592303654.5924294,IterationNumber=154500)\u001b[0m\n",
      "\u001b[34m[Epoch 132] Finished in 55.102s, training rmse: 0.0674, training loss: 0.0024\u001b[0m\n",
      "\u001b[34m[Epoch 133] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0037323187571018934,Timestamp=1592303678.1796718,IterationNumber=155000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002365399617701769,Timestamp=1592303701.9949908,IterationNumber=155500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0036388710141181946,Timestamp=1592303725.9882176,IterationNumber=156000)\u001b[0m\n",
      "\u001b[34m[Epoch 133] Finished in 55.651s, training rmse: 0.0658, training loss: 0.0023\u001b[0m\n",
      "\u001b[34m[Epoch 134] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002646674867719412,Timestamp=1592303749.7882164,IterationNumber=156500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0020252240356057882,Timestamp=1592303773.5995538,IterationNumber=157000)\u001b[0m\n",
      "\u001b[34m[Epoch 134] Finished in 55.433s, training rmse: 0.0674, training loss: 0.0024\u001b[0m\n",
      "\u001b[34m[Epoch 135] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001462107291445136,Timestamp=1592303797.5925715,IterationNumber=157500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017929854802787304,Timestamp=1592303821.9546442,IterationNumber=158000)\u001b[0m\n",
      "\u001b[34m[Epoch 135] Finished in 56.653s, training rmse: 0.0654, training loss: 0.0023\u001b[0m\n",
      "\u001b[34m[Epoch 136] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001099155517295003,Timestamp=1592303846.248416,IterationNumber=158500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0013219196116551757,Timestamp=1592303870.8496883,IterationNumber=159000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0023322845809161663,Timestamp=1592303895.4599497,IterationNumber=159500)\u001b[0m\n",
      "\u001b[34m[Epoch 136] Finished in 57.323s, training rmse: 0.0648, training loss: 0.0022\u001b[0m\n",
      "\u001b[34m[Epoch 137] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0021773241460323334,Timestamp=1592303920.4277058,IterationNumber=160000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0018517669523134828,Timestamp=1592303945.646683,IterationNumber=160500)\u001b[0m\n",
      "\u001b[34m[Epoch 137] Finished in 58.576s, training rmse: 0.0635, training loss: 0.0021\u001b[0m\n",
      "\u001b[34m[Epoch 138] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0035715827252715826,Timestamp=1592303971.009825,IterationNumber=161000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0015496525447815657,Timestamp=1592303996.4529114,IterationNumber=161500)\u001b[0m\n",
      "\u001b[34m[Epoch 138] Finished in 59.336s, training rmse: 0.0626, training loss: 0.0021\u001b[0m\n",
      "\u001b[34m[Epoch 139] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010170814348384738,Timestamp=1592304021.9364688,IterationNumber=162000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001910294871777296,Timestamp=1592304047.8133798,IterationNumber=162500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004216434899717569,Timestamp=1592304073.506274,IterationNumber=163000)\u001b[0m\n",
      "\u001b[34m[Epoch 139] Finished in 60.046s, training rmse: 0.0617, training loss: 0.0020\u001b[0m\n",
      "\u001b[34m[Epoch 140] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017637936398386955,Timestamp=1592304099.5253215,IterationNumber=163500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0016022046329453588,Timestamp=1592304125.9287117,IterationNumber=164000)\u001b[0m\n",
      "\u001b[34m[Epoch 140] Finished in 61.416s, training rmse: 0.0614, training loss: 0.0020\u001b[0m\n",
      "\u001b[34m[Epoch 141] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017519434913992882,Timestamp=1592304152.704113,IterationNumber=164500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010060095228254795,Timestamp=1592304179.7541244,IterationNumber=165000)\u001b[0m\n",
      "\u001b[34m[Epoch 141] Finished in 63.095s, training rmse: 0.0618, training loss: 0.0020\u001b[0m\n",
      "\u001b[34m[Epoch 142] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0025182326789945364,Timestamp=1592304207.019455,IterationNumber=165500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001005625817924738,Timestamp=1592304234.4601188,IterationNumber=166000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006188719999045134,Timestamp=1592304261.8407834,IterationNumber=166500)\u001b[0m\n",
      "\u001b[34m[Epoch 142] Finished in 64.172s, training rmse: 0.0603, training loss: 0.0019\u001b[0m\n",
      "\u001b[34m[Epoch 143] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001220995793119073,Timestamp=1592304289.9188106,IterationNumber=167000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008233539992943406,Timestamp=1592304318.0199835,IterationNumber=167500)\u001b[0m\n",
      "\u001b[34m[Epoch 143] Finished in 65.300s, training rmse: 0.0594, training loss: 0.0019\u001b[0m\n",
      "\u001b[34m[Epoch 144] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001924852724187076,Timestamp=1592304346.3114326,IterationNumber=168000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00170469144359231,Timestamp=1592304374.753483,IterationNumber=168500)\u001b[0m\n",
      "\u001b[34m[Epoch 144] Finished in 66.057s, training rmse: 0.0596, training loss: 0.0019\u001b[0m\n",
      "\u001b[34m[Epoch 145] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002962883561849594,Timestamp=1592304403.0926423,IterationNumber=169000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0020563537254929543,Timestamp=1592304432.2737756,IterationNumber=169500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014572577783837914,Timestamp=1592304461.224459,IterationNumber=170000)\u001b[0m\n",
      "\u001b[34m[Epoch 145] Finished in 67.846s, training rmse: 0.0586, training loss: 0.0018\u001b[0m\n",
      "\u001b[34m[Epoch 146] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002184745157137513,Timestamp=1592304490.7302334,IterationNumber=170500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017606258625164628,Timestamp=1592304520.3270602,IterationNumber=171000)\u001b[0m\n",
      "\u001b[34m[Epoch 146] Finished in 68.971s, training rmse: 0.0588, training loss: 0.0018\u001b[0m\n",
      "\u001b[34m[Epoch 147] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002579436171799898,Timestamp=1592304550.2346087,IterationNumber=171500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000914155738428235,Timestamp=1592304580.2600844,IterationNumber=172000)\u001b[0m\n",
      "\u001b[34m[Epoch 147] Finished in 69.963s, training rmse: 0.0571, training loss: 0.0017\u001b[0m\n",
      "\u001b[34m[Epoch 148] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0016969392308965325,Timestamp=1592304610.2849667,IterationNumber=172500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000863524794112891,Timestamp=1592304640.5651438,IterationNumber=173000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010817610891535878,Timestamp=1592304670.6304164,IterationNumber=173500)\u001b[0m\n",
      "\u001b[34m[Epoch 148] Finished in 70.345s, training rmse: 0.0577, training loss: 0.0018\u001b[0m\n",
      "\u001b[34m[Epoch 149] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012978847371414304,Timestamp=1592304700.958214,IterationNumber=174000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001876557245850563,Timestamp=1592304731.6311326,IterationNumber=174500)\u001b[0m\n",
      "\u001b[34m[Epoch 149] Finished in 71.216s, training rmse: 0.0568, training loss: 0.0017\u001b[0m\n",
      "\u001b[34m[Epoch 150] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0022460445761680603,Timestamp=1592304762.4405706,IterationNumber=175000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0025899680331349373,Timestamp=1592304793.4364047,IterationNumber=175500)\u001b[0m\n",
      "\u001b[34m[Epoch 150] Finished in 72.377s, training rmse: 0.0567, training loss: 0.0017\u001b[0m\n",
      "\u001b[34m[Epoch 151] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009362896671518683,Timestamp=1592304824.6722927,IterationNumber=176000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000716745329555124,Timestamp=1592304856.041673,IterationNumber=176500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000933441799134016,Timestamp=1592304887.310541,IterationNumber=177000)\u001b[0m\n",
      "\u001b[34m[Epoch 151] Finished in 72.940s, training rmse: 0.0572, training loss: 0.0017\u001b[0m\n",
      "\u001b[34m[Epoch 152] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000677030417136848,Timestamp=1592304919.0318863,IterationNumber=177500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0016771967057138681,Timestamp=1592304950.5841749,IterationNumber=178000)\u001b[0m\n",
      "\u001b[34m[Epoch 152] Finished in 73.621s, training rmse: 0.0540, training loss: 0.0015\u001b[0m\n",
      "\u001b[34m[Epoch 153] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001246955245733261,Timestamp=1592304981.9982324,IterationNumber=178500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0026095155626535416,Timestamp=1592305013.517209,IterationNumber=179000)\u001b[0m\n",
      "\u001b[34m[Epoch 153] Finished in 73.730s, training rmse: 0.0554, training loss: 0.0016\u001b[0m\n",
      "\u001b[34m[Epoch 154] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011825970141217113,Timestamp=1592305045.3593395,IterationNumber=179500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0013268595794215798,Timestamp=1592305077.2912445,IterationNumber=180000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001248075976036489,Timestamp=1592305109.2221112,IterationNumber=180500)\u001b[0m\n",
      "\u001b[34m[Epoch 154] Finished in 74.305s, training rmse: 0.0549, training loss: 0.0016\u001b[0m\n",
      "\u001b[34m[Epoch 155] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0025122619699686766,Timestamp=1592305141.2303946,IterationNumber=181000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0020537949167191982,Timestamp=1592305173.2738605,IterationNumber=181500)\u001b[0m\n",
      "\u001b[34m[Epoch 155] Finished in 74.685s, training rmse: 0.0542, training loss: 0.0016\u001b[0m\n",
      "\u001b[34m[Epoch 156] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014834258472546935,Timestamp=1592305205.355098,IterationNumber=182000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012115176068618894,Timestamp=1592305237.8858197,IterationNumber=182500)\u001b[0m\n",
      "\u001b[34m[Epoch 156] Finished in 75.348s, training rmse: 0.0533, training loss: 0.0015\u001b[0m\n",
      "\u001b[34m[Epoch 157] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012069043004885316,Timestamp=1592305270.0893626,IterationNumber=183000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004114419221878052,Timestamp=1592305302.22149,IterationNumber=183500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0018694598693400621,Timestamp=1592305334.57335,IterationNumber=184000)\u001b[0m\n",
      "\u001b[34m[Epoch 157] Finished in 75.180s, training rmse: 0.0526, training loss: 0.0015\u001b[0m\n",
      "\u001b[34m[Epoch 158] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0015021545113995671,Timestamp=1592305366.958107,IterationNumber=184500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0019547007977962494,Timestamp=1592305399.40376,IterationNumber=185000)\u001b[0m\n",
      "\u001b[34m[Epoch 158] Finished in 75.619s, training rmse: 0.0528, training loss: 0.0015\u001b[0m\n",
      "\u001b[34m[Epoch 159] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012769135646522045,Timestamp=1592305432.055771,IterationNumber=185500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000707490835338831,Timestamp=1592305464.5683491,IterationNumber=186000)\u001b[0m\n",
      "\u001b[34m[Epoch 159] Finished in 75.720s, training rmse: 0.0520, training loss: 0.0014\u001b[0m\n",
      "\u001b[34m[Epoch 160] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017103960271924734,Timestamp=1592305497.0057123,IterationNumber=186500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002796050626784563,Timestamp=1592305529.6107285,IterationNumber=187000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001019350136630237,Timestamp=1592305562.0907683,IterationNumber=187500)\u001b[0m\n",
      "\u001b[34m[Epoch 160] Finished in 75.774s, training rmse: 0.0513, training loss: 0.0014\u001b[0m\n",
      "\u001b[34m[Epoch 161] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0001412722049281001,Timestamp=1592305594.4964652,IterationNumber=188000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014919763198122382,Timestamp=1592305626.9761653,IterationNumber=188500)\u001b[0m\n",
      "\u001b[34m[Epoch 161] Finished in 75.853s, training rmse: 0.0503, training loss: 0.0013\u001b[0m\n",
      "\u001b[34m[Epoch 162] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007072547450661659,Timestamp=1592305659.7943192,IterationNumber=189000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0021465246099978685,Timestamp=1592305692.601319,IterationNumber=189500)\u001b[0m\n",
      "\u001b[34m[Epoch 162] Finished in 76.283s, training rmse: 0.0513, training loss: 0.0014\u001b[0m\n",
      "\u001b[34m[Epoch 163] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0029045837000012398,Timestamp=1592305725.2758722,IterationNumber=190000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008956968667916954,Timestamp=1592305758.1226757,IterationNumber=190500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000731161329895258,Timestamp=1592305791.019265,IterationNumber=191000)\u001b[0m\n",
      "\u001b[34m[Epoch 163] Finished in 76.606s, training rmse: 0.0514, training loss: 0.0014\u001b[0m\n",
      "\u001b[34m[Epoch 164] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00257496046833694,Timestamp=1592305823.970419,IterationNumber=191500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004411988484207541,Timestamp=1592305856.9886136,IterationNumber=192000)\u001b[0m\n",
      "\u001b[34m[Epoch 164] Finished in 76.649s, training rmse: 0.0504, training loss: 0.0013\u001b[0m\n",
      "\u001b[34m[Epoch 165] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0018215025775134563,Timestamp=1592305889.6949804,IterationNumber=192500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0013638854725286365,Timestamp=1592305922.447438,IterationNumber=193000)\u001b[0m\n",
      "\u001b[34m[Epoch 165] Finished in 76.550s, training rmse: 0.0493, training loss: 0.0013\u001b[0m\n",
      "\u001b[34m[Epoch 166] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012784400023519993,Timestamp=1592305955.5251856,IterationNumber=193500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014242364559322596,Timestamp=1592305988.427844,IterationNumber=194000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0025001915637403727,Timestamp=1592306021.2483778,IterationNumber=194500)\u001b[0m\n",
      "\u001b[34m[Epoch 166] Finished in 76.665s, training rmse: 0.0485, training loss: 0.0012\u001b[0m\n",
      "\u001b[34m[Epoch 167] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001469949260354042,Timestamp=1592306054.1622276,IterationNumber=195000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006128621753305197,Timestamp=1592306087.1546648,IterationNumber=195500)\u001b[0m\n",
      "\u001b[34m[Epoch 167] Finished in 76.800s, training rmse: 0.0508, training loss: 0.0014\u001b[0m\n",
      "\u001b[34m[Epoch 168] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010276439134031534,Timestamp=1592306120.2182748,IterationNumber=196000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0015943190082907677,Timestamp=1592306153.3526187,IterationNumber=196500)\u001b[0m\n",
      "\u001b[34m[Epoch 168] Finished in 76.982s, training rmse: 0.0487, training loss: 0.0013\u001b[0m\n",
      "\u001b[34m[Epoch 169] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0020628059282898903,Timestamp=1592306186.233825,IterationNumber=197000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005793161690235138,Timestamp=1592306218.875393,IterationNumber=197500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0024197380989789963,Timestamp=1592306251.9146821,IterationNumber=198000)\u001b[0m\n",
      "\u001b[34m[Epoch 169] Finished in 76.504s, training rmse: 0.0493, training loss: 0.0013\u001b[0m\n",
      "\u001b[34m[Epoch 170] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006108072120696306,Timestamp=1592306284.7763941,IterationNumber=198500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009193860460072756,Timestamp=1592306317.752997,IterationNumber=199000)\u001b[0m\n",
      "\u001b[34m[Epoch 170] Finished in 76.702s, training rmse: 0.0459, training loss: 0.0011\u001b[0m\n",
      "\u001b[34m[Epoch 171] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011041916441172361,Timestamp=1592306350.7683582,IterationNumber=199500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009287224384024739,Timestamp=1592306383.7397387,IterationNumber=200000)\u001b[0m\n",
      "\u001b[34m[Epoch 171] Finished in 76.903s, training rmse: 0.0473, training loss: 0.0012\u001b[0m\n",
      "\u001b[34m[Epoch 172] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000428960396675393,Timestamp=1592306416.6459322,IterationNumber=200500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0018112279940396547,Timestamp=1592306449.6257813,IterationNumber=201000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007080675568431616,Timestamp=1592306482.32578,IterationNumber=201500)\u001b[0m\n",
      "\u001b[34m[Epoch 172] Finished in 76.455s, training rmse: 0.0474, training loss: 0.0012\u001b[0m\n",
      "\u001b[34m[Epoch 173] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.001119267544709146,Timestamp=1592306514.7764723,IterationNumber=202000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0015954946866258979,Timestamp=1592306547.80536,IterationNumber=202500)\u001b[0m\n",
      "\u001b[34m[Epoch 173] Finished in 76.278s, training rmse: 0.0474, training loss: 0.0012\u001b[0m\n",
      "\u001b[34m[Epoch 174] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000619366008322686,Timestamp=1592306580.6028352,IterationNumber=203000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005123513983562589,Timestamp=1592306613.3081858,IterationNumber=203500)\u001b[0m\n",
      "\u001b[34m[Epoch 174] Finished in 76.222s, training rmse: 0.0464, training loss: 0.0011\u001b[0m\n",
      "\u001b[34m[Epoch 175] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0032155257649719715,Timestamp=1592306645.937581,IterationNumber=204000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006532212719321251,Timestamp=1592306678.7984726,IterationNumber=204500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008506160811521113,Timestamp=1592306711.5774398,IterationNumber=205000)\u001b[0m\n",
      "\u001b[34m[Epoch 175] Finished in 76.446s, training rmse: 0.0450, training loss: 0.0011\u001b[0m\n",
      "\u001b[34m[Epoch 176] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007268334738910198,Timestamp=1592306744.449059,IterationNumber=205500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004491413710638881,Timestamp=1592306777.1665957,IterationNumber=206000)\u001b[0m\n",
      "\u001b[34m[Epoch 176] Finished in 76.274s, training rmse: 0.0476, training loss: 0.0012\u001b[0m\n",
      "\u001b[34m[Epoch 177] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0013836903963238,Timestamp=1592306809.5856814,IterationNumber=206500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009063785546459258,Timestamp=1592306842.1042387,IterationNumber=207000)\u001b[0m\n",
      "\u001b[34m[Epoch 177] Finished in 75.962s, training rmse: 0.0446, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 178] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010320510482415557,Timestamp=1592306874.9543858,IterationNumber=207500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0015810431214049459,Timestamp=1592306907.8656986,IterationNumber=208000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008590847719460726,Timestamp=1592306940.5053241,IterationNumber=208500)\u001b[0m\n",
      "\u001b[34m[Epoch 178] Finished in 76.336s, training rmse: 0.0452, training loss: 0.0011\u001b[0m\n",
      "\u001b[34m[Epoch 179] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004342558386269957,Timestamp=1592306973.324215,IterationNumber=209000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010531326988711953,Timestamp=1592307006.5227897,IterationNumber=209500)\u001b[0m\n",
      "\u001b[34m[Epoch 179] Finished in 76.858s, training rmse: 0.0447, training loss: 0.0011\u001b[0m\n",
      "\u001b[34m[Epoch 180] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009782032575458288,Timestamp=1592307039.2597597,IterationNumber=210000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.002005600370466709,Timestamp=1592307072.1732879,IterationNumber=210500)\u001b[0m\n",
      "\u001b[34m[Epoch 180] Finished in 76.329s, training rmse: 0.0434, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 181] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.004029461182653904,Timestamp=1592307104.7809298,IterationNumber=211000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004001763300038874,Timestamp=1592307137.6015432,IterationNumber=211500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011743904324248433,Timestamp=1592307170.3367503,IterationNumber=212000)\u001b[0m\n",
      "\u001b[34m[Epoch 181] Finished in 76.432s, training rmse: 0.0447, training loss: 0.0011\u001b[0m\n",
      "\u001b[34m[Epoch 182] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0003558906028047204,Timestamp=1592307203.3693914,IterationNumber=212500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008293454884551466,Timestamp=1592307236.284595,IterationNumber=213000)\u001b[0m\n",
      "\u001b[34m[Epoch 182] Finished in 76.822s, training rmse: 0.0434, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 183] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006741677643731236,Timestamp=1592307269.3829505,IterationNumber=213500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004656743258237839,Timestamp=1592307302.7449136,IterationNumber=214000)\u001b[0m\n",
      "\u001b[34m[Epoch 183] Finished in 77.323s, training rmse: 0.0433, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 184] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0002662381448317319,Timestamp=1592307335.930687,IterationNumber=214500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009214230813086033,Timestamp=1592307369.0373952,IterationNumber=215000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011221830500289798,Timestamp=1592307401.801501,IterationNumber=215500)\u001b[0m\n",
      "\u001b[34m[Epoch 184] Finished in 76.890s, training rmse: 0.0434, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 185] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006640950450673699,Timestamp=1592307434.8389785,IterationNumber=216000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007521818624809384,Timestamp=1592307468.015377,IterationNumber=216500)\u001b[0m\n",
      "\u001b[34m[Epoch 185] Finished in 77.289s, training rmse: 0.0440, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 186] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00028870024834759533,Timestamp=1592307501.417463,IterationNumber=217000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0008662144537083805,Timestamp=1592307534.9579318,IterationNumber=217500)\u001b[0m\n",
      "\u001b[34m[Epoch 186] Finished in 78.268s, training rmse: 0.0414, training loss: 0.0009\u001b[0m\n",
      "\u001b[34m[Epoch 187] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006917946157045662,Timestamp=1592307568.7506459,IterationNumber=218000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004673340590670705,Timestamp=1592307602.499567,IterationNumber=218500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0012362165143713355,Timestamp=1592307636.0672991,IterationNumber=219000)\u001b[0m\n",
      "\u001b[34m[Epoch 187] Finished in 78.502s, training rmse: 0.0432, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 188] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004204178403597325,Timestamp=1592307669.8698092,IterationNumber=219500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005578861455433071,Timestamp=1592307703.2049916,IterationNumber=220000)\u001b[0m\n",
      "\u001b[34m[Epoch 188] Finished in 78.000s, training rmse: 0.0421, training loss: 0.0009\u001b[0m\n",
      "\u001b[34m[Epoch 189] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005023925332352519,Timestamp=1592307736.6377847,IterationNumber=220500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004564367118291557,Timestamp=1592307770.2064054,IterationNumber=221000)\u001b[0m\n",
      "\u001b[34m[Epoch 189] Finished in 78.442s, training rmse: 0.0428, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 190] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004296929982956499,Timestamp=1592307804.041298,IterationNumber=221500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00022801179147791117,Timestamp=1592307838.046933,IterationNumber=222000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005812885356135666,Timestamp=1592307872.0863113,IterationNumber=222500)\u001b[0m\n",
      "\u001b[34m[Epoch 190] Finished in 79.210s, training rmse: 0.0405, training loss: 0.0009\u001b[0m\n",
      "\u001b[34m[Epoch 191] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009247437119483948,Timestamp=1592307905.9422045,IterationNumber=223000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0010800933232530951,Timestamp=1592307939.9107876,IterationNumber=223500)\u001b[0m\n",
      "\u001b[34m[Epoch 191] Finished in 78.892s, training rmse: 0.0410, training loss: 0.0009\u001b[0m\n",
      "\u001b[34m[Epoch 192] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000864765141159296,Timestamp=1592307973.6518536,IterationNumber=224000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007832831470295787,Timestamp=1592308007.330461,IterationNumber=224500)\u001b[0m\n",
      "\u001b[34m[Epoch 192] Finished in 78.550s, training rmse: 0.0424, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 193] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004193370696157217,Timestamp=1592308041.1055284,IterationNumber=225000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.000732800574041903,Timestamp=1592308075.3388464,IterationNumber=225500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005588081548921764,Timestamp=1592308109.6691792,IterationNumber=226000)\u001b[0m\n",
      "\u001b[34m[Epoch 193] Finished in 79.806s, training rmse: 0.0425, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 194] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011374135501682758,Timestamp=1592308144.04032,IterationNumber=226500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0006451825611293316,Timestamp=1592308178.3293202,IterationNumber=227000)\u001b[0m\n",
      "\u001b[34m[Epoch 194] Finished in 79.934s, training rmse: 0.0398, training loss: 0.0008\u001b[0m\n",
      "\u001b[34m[Epoch 195] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00032064307015389204,Timestamp=1592308212.745838,IterationNumber=227500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0009628146653994918,Timestamp=1592308247.4093378,IterationNumber=228000)\u001b[0m\n",
      "\u001b[34m[Epoch 195] Finished in 80.740s, training rmse: 0.0424, training loss: 0.0010\u001b[0m\n",
      "\u001b[34m[Epoch 196] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0011892212787643075,Timestamp=1592308282.1295447,IterationNumber=228500)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0004172454937361181,Timestamp=1592308316.504207,IterationNumber=229000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0017814722377806902,Timestamp=1592308350.8590949,IterationNumber=229500)\u001b[0m\n",
      "\u001b[34m[Epoch 196] Finished in 80.143s, training rmse: 0.0402, training loss: 0.0009\u001b[0m\n",
      "\u001b[34m[Epoch 197] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.00036936873220838606,Timestamp=1592308385.523634,IterationNumber=230000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007555098854936659,Timestamp=1592308420.416277,IterationNumber=230500)\u001b[0m\n",
      "\u001b[34m[Epoch 197] Finished in 80.970s, training rmse: 0.0387, training loss: 0.0008\u001b[0m\n",
      "\u001b[34m[Epoch 198] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0007220029947347939,Timestamp=1592308455.0281925,IterationNumber=231000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0014119278639554977,Timestamp=1592308489.6346655,IterationNumber=231500)\u001b[0m\n",
      "\u001b[34m[Epoch 198] Finished in 80.620s, training rmse: 0.0409, training loss: 0.0009\u001b[0m\n",
      "\u001b[34m[Epoch 199] Begin, current learning rate: 0.0035\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0005342700169421732,Timestamp=1592308524.2548058,IterationNumber=232000)\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='l2loss0_output_0_GLOBAL',Value=0.0003365842276252806,Timestamp=1592308559.0536568,IterationNumber=232500)\u001b[0m\n",
      "\u001b[34m[Epoch 199] Finished in 80.683s, training rmse: 0.0425, training loss: 0.0010\u001b[0m\n",
      "\u001b[34mTrain finished using total 9659s with 200 epochs. training rmse: 0.0425, training loss: 0.0010\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Training end\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Model directory clean up, only keeps the best model\u001b[0m\n",
      "\u001b[34mINFO:root:[### train ###] Emitting metrics\u001b[0m\n",
      "\u001b[34mtraining rmse: 0.042493549427377306\u001b[0m\n",
      "\u001b[34mtraining loss: 0.0010052533474555914\u001b[0m\n",
      "\u001b[34m[2020-06-16 11:56:33.464 ip-10-0-145-204.eu-west-1.compute.internal:102 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-06-16 11:56:33,590 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-16 11:57:33 Uploading - Uploading generated training model\n",
      "2020-06-16 11:57:33 Completed - Training job completed\n",
      "Training seconds: 9772\n",
      "Billable seconds: 9772\n"
     ]
    }
   ],
   "source": [
    "# rul_estimator.fit(inputs=data_channels)\n",
    "# job_name = rul_estimator._current_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue by demonstrating than the hyperparameter tuning job also works with a custom script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "\n",
    "rul_lstm_tuner = HyperparameterTuner(\n",
    "    estimator = rul_estimator,                    # The estimator object to use as the basis for the training jobs.\n",
    "    metric_definitions=[{                         # We want to minimize the RMSE of the predicted RUL\n",
    "        'Name': 'train:rmse', \n",
    "        'Regex': 'training rmse: (\\S+)'\n",
    "    }],\n",
    "    objective_metric_name = 'train:rmse',         # The metric used to compare trained models (RMSE).\n",
    "    objective_type = 'Minimize',                  # We wish to minimize this error metric.\n",
    "    max_jobs = 20,                                # The total number of models to train\n",
    "    max_parallel_jobs = 2,                        # The number of models to train in parallel\n",
    "    hyperparameter_ranges = {\n",
    "        'num-layers': IntegerParameter(3, 8),\n",
    "        'hidden-size': IntegerParameter(10, 200),\n",
    "        'learning-rate': ContinuousParameter(1e-4, 1e-2),\n",
    "        'batch-size': CategoricalParameter([16, 32, 64, 128, 256]),\n",
    "    },\n",
    "    base_tuning_job_name = training_job_name + '-tuner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nasa-rul-lstm-tuner-200615-1857'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul_lstm_tuner.fit(inputs=data_channels, logs=True)\n",
    "rul_lstm_tuner._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 training jobs have completed\n",
      "Number of training jobs with valid objective: 19\n",
      "{'lowest': 0.11708906292915344, 'highest': 0.3347015976905823}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-size</th>\n",
       "      <th>hidden-size</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>num-layers</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"16\"</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-012-4f6e2849</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.117089</td>\n",
       "      <td>2020-06-15 21:51:14+00:00</td>\n",
       "      <td>2020-06-15 22:15:28+00:00</td>\n",
       "      <td>1454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"16\"</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-008-15f61318</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.122048</td>\n",
       "      <td>2020-06-15 20:29:27+00:00</td>\n",
       "      <td>2020-06-15 20:59:19+00:00</td>\n",
       "      <td>1792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"64\"</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-007-97894b06</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.122478</td>\n",
       "      <td>2020-06-15 20:23:02+00:00</td>\n",
       "      <td>2020-06-15 20:52:11+00:00</td>\n",
       "      <td>1749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"16\"</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>6.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-019-d3a754ca</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>2020-06-15 23:59:29+00:00</td>\n",
       "      <td>2020-06-16 01:12:51+00:00</td>\n",
       "      <td>4402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"32\"</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-016-0a91147c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.123287</td>\n",
       "      <td>2020-06-15 23:15:22+00:00</td>\n",
       "      <td>2020-06-15 23:21:17+00:00</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"32\"</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-013-91555df5</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.123455</td>\n",
       "      <td>2020-06-15 21:55:34+00:00</td>\n",
       "      <td>2020-06-15 23:12:13+00:00</td>\n",
       "      <td>4599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"32\"</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-005-a19076d2</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.123480</td>\n",
       "      <td>2020-06-15 19:58:26+00:00</td>\n",
       "      <td>2020-06-15 20:20:29+00:00</td>\n",
       "      <td>1323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"64\"</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-015-44664b8f</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.124638</td>\n",
       "      <td>2020-06-15 23:10:33+00:00</td>\n",
       "      <td>2020-06-15 23:21:29+00:00</td>\n",
       "      <td>656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>6.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-003-79ab1c18</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.125434</td>\n",
       "      <td>2020-06-15 19:08:06+00:00</td>\n",
       "      <td>2020-06-15 19:52:33+00:00</td>\n",
       "      <td>2667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"256\"</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-014-b11beeb8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.125607</td>\n",
       "      <td>2020-06-15 22:20:11+00:00</td>\n",
       "      <td>2020-06-15 23:01:31+00:00</td>\n",
       "      <td>2480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"32\"</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-004-b43c2aeb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.126788</td>\n",
       "      <td>2020-06-15 19:37:08+00:00</td>\n",
       "      <td>2020-06-15 20:09:33+00:00</td>\n",
       "      <td>1945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-006-72a7cebd</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.126914</td>\n",
       "      <td>2020-06-15 20:13:08+00:00</td>\n",
       "      <td>2020-06-15 20:26:36+00:00</td>\n",
       "      <td>808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"32\"</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-018-1e3a9094</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.127361</td>\n",
       "      <td>2020-06-15 23:24:03+00:00</td>\n",
       "      <td>2020-06-15 23:51:47+00:00</td>\n",
       "      <td>1664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-011-68728f49</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.130582</td>\n",
       "      <td>2020-06-15 21:08:26+00:00</td>\n",
       "      <td>2020-06-15 21:52:53+00:00</td>\n",
       "      <td>2667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"256\"</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-001-629d5a46</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>2020-06-15 18:59:57+00:00</td>\n",
       "      <td>2020-06-15 19:31:15+00:00</td>\n",
       "      <td>1878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>8.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-009-9d8beed0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.131134</td>\n",
       "      <td>2020-06-15 20:54:46+00:00</td>\n",
       "      <td>2020-06-15 21:05:42+00:00</td>\n",
       "      <td>656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-010-89792b82</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.131776</td>\n",
       "      <td>2020-06-15 21:03:12+00:00</td>\n",
       "      <td>2020-06-15 21:47:29+00:00</td>\n",
       "      <td>2657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"256\"</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-017-d335b91a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.184431</td>\n",
       "      <td>2020-06-15 23:23:42+00:00</td>\n",
       "      <td>2020-06-16 00:30:32+00:00</td>\n",
       "      <td>4010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"256\"</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nasa-rul-lstm-tuner-200615-1857-002-18a9e872</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.334702</td>\n",
       "      <td>2020-06-15 19:00:03+00:00</td>\n",
       "      <td>2020-06-15 19:05:10+00:00</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch-size  hidden-size  learning-rate  num-layers  \\\n",
       "8        \"16\"        122.0       0.003471         3.0   \n",
       "12       \"16\"         76.0       0.000341         7.0   \n",
       "13       \"64\"        182.0       0.002367         3.0   \n",
       "1        \"16\"        144.0       0.008509         6.0   \n",
       "4        \"32\"         18.0       0.001126         3.0   \n",
       "7        \"32\"        162.0       0.000984         7.0   \n",
       "15       \"32\"         85.0       0.002666         4.0   \n",
       "5        \"64\"         30.0       0.004591         7.0   \n",
       "17      \"128\"        147.0       0.003274         6.0   \n",
       "6       \"256\"        157.0       0.007255         5.0   \n",
       "16       \"32\"         87.0       0.002792         4.0   \n",
       "14      \"128\"         97.0       0.000374         3.0   \n",
       "2        \"32\"         71.0       0.000190         8.0   \n",
       "9       \"128\"        164.0       0.000113         5.0   \n",
       "19      \"256\"         98.0       0.001865         7.0   \n",
       "11      \"128\"         30.0       0.001686         8.0   \n",
       "10      \"128\"        166.0       0.000108         5.0   \n",
       "3       \"256\"        180.0       0.000100         7.0   \n",
       "18      \"256\"         10.0       0.000468         7.0   \n",
       "\n",
       "                                 TrainingJobName TrainingJobStatus  \\\n",
       "8   nasa-rul-lstm-tuner-200615-1857-012-4f6e2849         Completed   \n",
       "12  nasa-rul-lstm-tuner-200615-1857-008-15f61318         Completed   \n",
       "13  nasa-rul-lstm-tuner-200615-1857-007-97894b06         Completed   \n",
       "1   nasa-rul-lstm-tuner-200615-1857-019-d3a754ca         Completed   \n",
       "4   nasa-rul-lstm-tuner-200615-1857-016-0a91147c         Completed   \n",
       "7   nasa-rul-lstm-tuner-200615-1857-013-91555df5         Completed   \n",
       "15  nasa-rul-lstm-tuner-200615-1857-005-a19076d2         Completed   \n",
       "5   nasa-rul-lstm-tuner-200615-1857-015-44664b8f         Completed   \n",
       "17  nasa-rul-lstm-tuner-200615-1857-003-79ab1c18         Completed   \n",
       "6   nasa-rul-lstm-tuner-200615-1857-014-b11beeb8         Completed   \n",
       "16  nasa-rul-lstm-tuner-200615-1857-004-b43c2aeb         Completed   \n",
       "14  nasa-rul-lstm-tuner-200615-1857-006-72a7cebd         Completed   \n",
       "2   nasa-rul-lstm-tuner-200615-1857-018-1e3a9094         Completed   \n",
       "9   nasa-rul-lstm-tuner-200615-1857-011-68728f49         Completed   \n",
       "19  nasa-rul-lstm-tuner-200615-1857-001-629d5a46         Completed   \n",
       "11  nasa-rul-lstm-tuner-200615-1857-009-9d8beed0         Completed   \n",
       "10  nasa-rul-lstm-tuner-200615-1857-010-89792b82         Completed   \n",
       "3   nasa-rul-lstm-tuner-200615-1857-017-d335b91a         Completed   \n",
       "18  nasa-rul-lstm-tuner-200615-1857-002-18a9e872         Completed   \n",
       "\n",
       "    FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "8              0.117089 2020-06-15 21:51:14+00:00 2020-06-15 22:15:28+00:00   \n",
       "12             0.122048 2020-06-15 20:29:27+00:00 2020-06-15 20:59:19+00:00   \n",
       "13             0.122478 2020-06-15 20:23:02+00:00 2020-06-15 20:52:11+00:00   \n",
       "1              0.123188 2020-06-15 23:59:29+00:00 2020-06-16 01:12:51+00:00   \n",
       "4              0.123287 2020-06-15 23:15:22+00:00 2020-06-15 23:21:17+00:00   \n",
       "7              0.123455 2020-06-15 21:55:34+00:00 2020-06-15 23:12:13+00:00   \n",
       "15             0.123480 2020-06-15 19:58:26+00:00 2020-06-15 20:20:29+00:00   \n",
       "5              0.124638 2020-06-15 23:10:33+00:00 2020-06-15 23:21:29+00:00   \n",
       "17             0.125434 2020-06-15 19:08:06+00:00 2020-06-15 19:52:33+00:00   \n",
       "6              0.125607 2020-06-15 22:20:11+00:00 2020-06-15 23:01:31+00:00   \n",
       "16             0.126788 2020-06-15 19:37:08+00:00 2020-06-15 20:09:33+00:00   \n",
       "14             0.126914 2020-06-15 20:13:08+00:00 2020-06-15 20:26:36+00:00   \n",
       "2              0.127361 2020-06-15 23:24:03+00:00 2020-06-15 23:51:47+00:00   \n",
       "9              0.130582 2020-06-15 21:08:26+00:00 2020-06-15 21:52:53+00:00   \n",
       "19             0.130909 2020-06-15 18:59:57+00:00 2020-06-15 19:31:15+00:00   \n",
       "11             0.131134 2020-06-15 20:54:46+00:00 2020-06-15 21:05:42+00:00   \n",
       "10             0.131776 2020-06-15 21:03:12+00:00 2020-06-15 21:47:29+00:00   \n",
       "3              0.184431 2020-06-15 23:23:42+00:00 2020-06-16 00:30:32+00:00   \n",
       "18             0.334702 2020-06-15 19:00:03+00:00 2020-06-15 19:05:10+00:00   \n",
       "\n",
       "    TrainingElapsedTimeSeconds  \n",
       "8                       1454.0  \n",
       "12                      1792.0  \n",
       "13                      1749.0  \n",
       "1                       4402.0  \n",
       "4                        355.0  \n",
       "7                       4599.0  \n",
       "15                      1323.0  \n",
       "5                        656.0  \n",
       "17                      2667.0  \n",
       "6                       2480.0  \n",
       "16                      1945.0  \n",
       "14                       808.0  \n",
       "2                       1664.0  \n",
       "9                       2667.0  \n",
       "19                      1878.0  \n",
       "11                       656.0  \n",
       "10                      2657.0  \n",
       "3                       4010.0  \n",
       "18                       307.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lstm_utils import get_tuner_results\n",
    "#tuner_results = get_tuner_results(rul_lstm_tuner._current_job_name)\n",
    "tuner_results = get_tuner_results('nasa-rul-lstm-tuner-200615-1857')\n",
    "tuner_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous table is sorted by increasing RMSE: the first row is related to the training job with the best RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = tuner_results.iloc[0]['TrainingJobName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing data for the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa-rul-lstm-2020-06-16-09-12-37-314\n",
      "Stored 'job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "print(job_name)\n",
    "\n",
    "%store job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persisting these data to disk\n",
    "This is useful in case you want to be able to execute each notebook independantly (from one session to another) and don't want to reexecute every notebooks whenever you want to focus on a particular step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the best training job name to disk:\n",
    "with open(os.path.join(PROCESSED_DATA, 'job_name.txt'), 'w') as f:\n",
    "    f.write(job_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
